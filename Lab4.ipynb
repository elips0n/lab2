{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrPKwHSADclF"
      },
      "source": [
        "Импорты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cThXfXdDQyE"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt \n"
      ],
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dlDdnJfol5x"
      },
      "source": [
        "Инструменты для загрузки картинок"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTpBA-MZoqC_"
      },
      "source": [
        "\n",
        "def load():\n",
        "    path = \"/content/*.*\"\n",
        "    \"\"\"Загрузка картинок без обрезания\"\"\"\n",
        "    return [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(path))]\n",
        "\n",
        "def split(img):\n",
        "    \"\"\"Разбиение картинок на маленькие\"\"\"\n",
        "    size = 10\n",
        "    img_height = img.shape[0] // size\n",
        "    img_width = img.shape[1] // size\n",
        "    res = []\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            res.append(img[i * img_height:(i+1) * img_height, j * img_width:(j+1) * img_width])\n",
        "    return res\n",
        "\n",
        "def squeeze(split_img):\n",
        "    \"\"\"Сжатие 32 на 32\"\"\"\n",
        "    return cv2.resize(split_img, (32, 32))\n",
        "\n",
        "def img_to1d(img):\n",
        "    \"\"\"Трансформация к 1 мерному\"\"\"\n",
        "    return img.ravel()\n",
        "\n",
        "def normalize(img):\n",
        "    \"\"\"Нормализация каждого пикселя к отрезку [0, 1]\"\"\"\n",
        "    return img / 255.0\n",
        "\n",
        "def process_img(img):\n",
        "    \"\"\"Обработка исходной картинка\"\"\"\n",
        "    return (squeeze(img))\n",
        "\n",
        "def img_to1d(img):\n",
        "    \"\"\"Трансформация к 1 мерному\"\"\"\n",
        "    return img.ravel()"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqmxUPMytOlo"
      },
      "source": [
        "Загрузим картинки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "EJa2MYT1tQld",
        "outputId": "a4b860ce-717f-466f-a449-35a39ae67d42"
      },
      "source": [
        "labels = np.array([0]*300+[1]*300+[2]*300+[3]*300+[4]*300)\n",
        "src_imgs = load()\n",
        "label = 0\n",
        "features = []\n",
        "for img in src_imgs:\n",
        "    split_imgs = split(img)\n",
        "    for split_img in split_imgs:\n",
        "        features.append(process_img(split_img))\n",
        "data_set = features\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(0,6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(data_set[i], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Ground Truth: {}\".format(labels[i]))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "for i in range(0, len(data_set)):\n",
        "    data_set[i] = normalize(data_set[i])"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GpfDlhDoq7T"
      },
      "source": [
        "А теперь будем разбивать на тестовую выборку и на обучающую.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rzm7mo8o9Gb",
        "outputId": "02100df7-e614-4b2e-ec62-e30b625b19a5"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data_set, labels, test_size=0.33, random_state=42)\n",
        "x_train[0]"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.98431373, 0.97254902, 0.98039216, ..., 0.98823529, 0.45098039,\n",
              "        0.83529412],\n",
              "       [0.96078431, 0.98431373, 0.96862745, ..., 0.94509804, 0.43529412,\n",
              "        0.89019608],\n",
              "       [0.98039216, 0.96470588, 0.97647059, ..., 0.98823529, 0.45882353,\n",
              "        0.88235294],\n",
              "       ...,\n",
              "       [0.96078431, 0.97254902, 0.96078431, ..., 0.95686275, 0.40784314,\n",
              "        0.96078431],\n",
              "       [0.77254902, 0.78823529, 0.81176471, ..., 0.94117647, 0.4       ,\n",
              "        0.90588235],\n",
              "       [0.81960784, 0.81960784, 0.81568627, ..., 0.72156863, 0.70980392,\n",
              "        0.71372549]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8GsmpruGmh-"
      },
      "source": [
        "Берем датасет "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dSlehufGoIt",
        "outputId": "31a903dd-09fc-4543-85c0-f0d504bca9c7"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 5\n",
        "input_shape = (32, 32, 1)\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# # convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (1005, 32, 32, 1)\n",
            "1005 train samples\n",
            "495 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09-LpFjtGsmo"
      },
      "source": [
        "Теперь создаем нейросетку и треним ее"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbmPlqYgGvnU",
        "outputId": "7aca517c-4a0b-420b-d7f5-578822ef6591"
      },
      "source": [
        "\n",
        "#Сверточная сеть\n",
        "model1 = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "# Полносвязная сеть многослойная\n",
        "model2 =  keras.Sequential([\n",
        "  keras.Input(shape=1024),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(num_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "# Полносвязная сеть однослойная\n",
        "model3 =  keras.Sequential([\n",
        "  keras.Input(shape=1024),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(num_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model3.summary()\n"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_46 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 5)                 11525     \n",
            "=================================================================\n",
            "Total params: 30,341\n",
            "Trainable params: 30,341\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_62 (Dense)             (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 70,085\n",
            "Trainable params: 70,085\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_65 (Dense)             (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 65,925\n",
            "Trainable params: 65,925\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKrbTRSjG_Xo"
      },
      "source": [
        "Теперь будем тренировать convolutional нейросеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAMbK4cnHBOq",
        "outputId": "a6f9e897-93f2-43f4-caaa-1e0aa8e04fa5"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 80\n",
        "\n",
        "model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model1.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "8/8 [==============================] - 2s 144ms/step - loss: 1.6134 - accuracy: 0.2091 - val_loss: 1.6055 - val_accuracy: 0.2178\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.6087 - accuracy: 0.2046 - val_loss: 1.6026 - val_accuracy: 0.2079\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.6082 - accuracy: 0.2080 - val_loss: 1.6007 - val_accuracy: 0.2178\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 1.6034 - accuracy: 0.2080 - val_loss: 1.5970 - val_accuracy: 0.2178\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5981 - accuracy: 0.2246 - val_loss: 1.5912 - val_accuracy: 0.2178\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5902 - accuracy: 0.2743 - val_loss: 1.5828 - val_accuracy: 0.4356\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5807 - accuracy: 0.3042 - val_loss: 1.5729 - val_accuracy: 0.4554\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5745 - accuracy: 0.3429 - val_loss: 1.5592 - val_accuracy: 0.4851\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.5542 - accuracy: 0.3894 - val_loss: 1.5433 - val_accuracy: 0.4455\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.5372 - accuracy: 0.4038 - val_loss: 1.5226 - val_accuracy: 0.4356\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.5136 - accuracy: 0.3794 - val_loss: 1.4966 - val_accuracy: 0.3960\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.4755 - accuracy: 0.4502 - val_loss: 1.4542 - val_accuracy: 0.5644\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.4373 - accuracy: 0.5343 - val_loss: 1.4081 - val_accuracy: 0.5743\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.3925 - accuracy: 0.5454 - val_loss: 1.3607 - val_accuracy: 0.5941\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.3364 - accuracy: 0.5819 - val_loss: 1.2988 - val_accuracy: 0.6040\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.2700 - accuracy: 0.6272 - val_loss: 1.2358 - val_accuracy: 0.5842\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.1967 - accuracy: 0.6361 - val_loss: 1.1632 - val_accuracy: 0.6535\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 1.1342 - accuracy: 0.6338 - val_loss: 1.1046 - val_accuracy: 0.6832\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 1.0741 - accuracy: 0.6527 - val_loss: 1.0434 - val_accuracy: 0.6634\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 1s 127ms/step - loss: 1.0118 - accuracy: 0.6648 - val_loss: 0.9754 - val_accuracy: 0.6931\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.9456 - accuracy: 0.7024 - val_loss: 0.9305 - val_accuracy: 0.6733\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.9039 - accuracy: 0.6858 - val_loss: 0.9168 - val_accuracy: 0.7129\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.8798 - accuracy: 0.7179 - val_loss: 0.8445 - val_accuracy: 0.7327\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.8109 - accuracy: 0.7445 - val_loss: 0.7844 - val_accuracy: 0.7426\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.7559 - accuracy: 0.7533 - val_loss: 0.7572 - val_accuracy: 0.7327\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.7071 - accuracy: 0.7588 - val_loss: 0.7012 - val_accuracy: 0.7525\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.6927 - accuracy: 0.7721 - val_loss: 0.6713 - val_accuracy: 0.7921\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.6385 - accuracy: 0.7810 - val_loss: 0.6686 - val_accuracy: 0.7822\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 0.6131 - accuracy: 0.8086 - val_loss: 0.6372 - val_accuracy: 0.7723\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.5896 - accuracy: 0.8053 - val_loss: 0.5883 - val_accuracy: 0.7723\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 0.5881 - accuracy: 0.7965 - val_loss: 0.5713 - val_accuracy: 0.7921\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 0.5447 - accuracy: 0.8197 - val_loss: 0.5584 - val_accuracy: 0.8218\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.5336 - accuracy: 0.8230 - val_loss: 0.5341 - val_accuracy: 0.8119\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.5251 - accuracy: 0.8230 - val_loss: 0.5150 - val_accuracy: 0.8317\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 0.4992 - accuracy: 0.8330 - val_loss: 0.5056 - val_accuracy: 0.8218\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.4645 - accuracy: 0.8573 - val_loss: 0.4873 - val_accuracy: 0.8515\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.4654 - accuracy: 0.8462 - val_loss: 0.4808 - val_accuracy: 0.8614\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 0.4548 - accuracy: 0.8518 - val_loss: 0.4714 - val_accuracy: 0.8515\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.4400 - accuracy: 0.8518 - val_loss: 0.4484 - val_accuracy: 0.8713\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 0.4446 - accuracy: 0.8518 - val_loss: 0.4360 - val_accuracy: 0.8911\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 0.4204 - accuracy: 0.8584 - val_loss: 0.4245 - val_accuracy: 0.8713\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.4367 - accuracy: 0.8551 - val_loss: 0.4114 - val_accuracy: 0.8911\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 0.3995 - accuracy: 0.8717 - val_loss: 0.4092 - val_accuracy: 0.9208\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.3876 - accuracy: 0.8684 - val_loss: 0.4032 - val_accuracy: 0.9010\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.4199 - accuracy: 0.8639 - val_loss: 0.3949 - val_accuracy: 0.9010\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.3863 - accuracy: 0.8783 - val_loss: 0.3775 - val_accuracy: 0.9010\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.3839 - accuracy: 0.8739 - val_loss: 0.3706 - val_accuracy: 0.9208\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 0.3797 - accuracy: 0.8717 - val_loss: 0.3644 - val_accuracy: 0.9307\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.3402 - accuracy: 0.8894 - val_loss: 0.3562 - val_accuracy: 0.9208\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.3416 - accuracy: 0.8872 - val_loss: 0.3494 - val_accuracy: 0.9307\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.3269 - accuracy: 0.8949 - val_loss: 0.3503 - val_accuracy: 0.9307\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.3456 - accuracy: 0.8805 - val_loss: 0.3359 - val_accuracy: 0.9307\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.3162 - accuracy: 0.9038 - val_loss: 0.3264 - val_accuracy: 0.9307\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.3083 - accuracy: 0.9137 - val_loss: 0.3358 - val_accuracy: 0.9307\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.3025 - accuracy: 0.9126 - val_loss: 0.3211 - val_accuracy: 0.9406\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.3110 - accuracy: 0.9049 - val_loss: 0.3171 - val_accuracy: 0.9505\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.3040 - accuracy: 0.9137 - val_loss: 0.3088 - val_accuracy: 0.9406\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.2895 - accuracy: 0.9159 - val_loss: 0.3027 - val_accuracy: 0.9505\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.3089 - accuracy: 0.8971 - val_loss: 0.3022 - val_accuracy: 0.9307\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.2691 - accuracy: 0.9237 - val_loss: 0.2960 - val_accuracy: 0.9307\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.2677 - accuracy: 0.9082 - val_loss: 0.2946 - val_accuracy: 0.9307\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.2661 - accuracy: 0.9137 - val_loss: 0.2899 - val_accuracy: 0.9505\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.2720 - accuracy: 0.9060 - val_loss: 0.2809 - val_accuracy: 0.9505\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.2660 - accuracy: 0.9170 - val_loss: 0.2866 - val_accuracy: 0.9604\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.2631 - accuracy: 0.9204 - val_loss: 0.2787 - val_accuracy: 0.9505\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.2626 - accuracy: 0.9259 - val_loss: 0.2744 - val_accuracy: 0.9505\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.2716 - accuracy: 0.9159 - val_loss: 0.2694 - val_accuracy: 0.9604\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.2459 - accuracy: 0.9204 - val_loss: 0.2821 - val_accuracy: 0.9604\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.2579 - accuracy: 0.9248 - val_loss: 0.2864 - val_accuracy: 0.9505\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.2544 - accuracy: 0.9204 - val_loss: 0.2876 - val_accuracy: 0.9406\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.2347 - accuracy: 0.9347 - val_loss: 0.2714 - val_accuracy: 0.9604\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 0.2345 - accuracy: 0.9347 - val_loss: 0.2606 - val_accuracy: 0.9505\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.2260 - accuracy: 0.9358 - val_loss: 0.2705 - val_accuracy: 0.9406\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 0.2197 - accuracy: 0.9325 - val_loss: 0.2661 - val_accuracy: 0.9604\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.2363 - accuracy: 0.9358 - val_loss: 0.2645 - val_accuracy: 0.9406\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.2092 - accuracy: 0.9392 - val_loss: 0.2522 - val_accuracy: 0.9604\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.2190 - accuracy: 0.9292 - val_loss: 0.2489 - val_accuracy: 0.9604\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 0.2040 - accuracy: 0.9425 - val_loss: 0.2478 - val_accuracy: 0.9505\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.2268 - accuracy: 0.9292 - val_loss: 0.2494 - val_accuracy: 0.9604\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.2037 - accuracy: 0.9436 - val_loss: 0.2469 - val_accuracy: 0.9604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd61360790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izrpErfgHE3I"
      },
      "source": [
        "Проверяем convolutional нейросеть:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uInfS1vcHGjz",
        "outputId": "8ec8fdeb-2136-4f86-f8f7-54a45978be36"
      },
      "source": [
        "score = model1.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3456214666366577\n",
            "Test accuracy: 0.9070706963539124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTSlZno3FltC"
      },
      "source": [
        "Будем тренировать многослойную полносвязную нейросеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8YcP0EE7x60",
        "outputId": "5cf81309-824f-44c4-e54f-b5d9f1232cc6"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 400\n",
        "\n",
        "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "x_train1 = x_train.reshape(int(1500*0.67),1024)\n",
        "model2.fit(x_train1, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "8/8 [==============================] - 1s 27ms/step - loss: 1.7730 - accuracy: 0.2013 - val_loss: 1.6216 - val_accuracy: 0.2178\n",
            "Epoch 2/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.6934 - accuracy: 0.1991 - val_loss: 1.5962 - val_accuracy: 0.2574\n",
            "Epoch 3/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6223 - accuracy: 0.2279 - val_loss: 1.6225 - val_accuracy: 0.2277\n",
            "Epoch 4/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6093 - accuracy: 0.2356 - val_loss: 1.5804 - val_accuracy: 0.3663\n",
            "Epoch 5/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.5979 - accuracy: 0.2677 - val_loss: 1.5804 - val_accuracy: 0.2079\n",
            "Epoch 6/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5866 - accuracy: 0.2566 - val_loss: 1.5743 - val_accuracy: 0.4059\n",
            "Epoch 7/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5797 - accuracy: 0.3440 - val_loss: 1.5854 - val_accuracy: 0.1782\n",
            "Epoch 8/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5965 - accuracy: 0.1980 - val_loss: 1.5582 - val_accuracy: 0.3069\n",
            "Epoch 9/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5736 - accuracy: 0.2843 - val_loss: 1.5531 - val_accuracy: 0.3069\n",
            "Epoch 10/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5605 - accuracy: 0.3075 - val_loss: 1.5567 - val_accuracy: 0.2475\n",
            "Epoch 11/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5793 - accuracy: 0.2323 - val_loss: 1.5371 - val_accuracy: 0.3168\n",
            "Epoch 12/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5445 - accuracy: 0.2500 - val_loss: 1.5123 - val_accuracy: 0.3663\n",
            "Epoch 13/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5267 - accuracy: 0.2987 - val_loss: 1.5006 - val_accuracy: 0.2871\n",
            "Epoch 14/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5071 - accuracy: 0.3794 - val_loss: 1.5300 - val_accuracy: 0.2673\n",
            "Epoch 15/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5055 - accuracy: 0.3352 - val_loss: 1.4581 - val_accuracy: 0.3465\n",
            "Epoch 16/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4825 - accuracy: 0.3739 - val_loss: 1.4336 - val_accuracy: 0.5050\n",
            "Epoch 17/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4574 - accuracy: 0.3927 - val_loss: 1.4868 - val_accuracy: 0.2970\n",
            "Epoch 18/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5091 - accuracy: 0.2931 - val_loss: 1.4138 - val_accuracy: 0.3960\n",
            "Epoch 19/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.4475 - accuracy: 0.3485 - val_loss: 1.4859 - val_accuracy: 0.3663\n",
            "Epoch 20/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5163 - accuracy: 0.3119 - val_loss: 1.4215 - val_accuracy: 0.4257\n",
            "Epoch 21/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4351 - accuracy: 0.3485 - val_loss: 1.4040 - val_accuracy: 0.4059\n",
            "Epoch 22/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4018 - accuracy: 0.4126 - val_loss: 1.4585 - val_accuracy: 0.3168\n",
            "Epoch 23/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4042 - accuracy: 0.3872 - val_loss: 1.3544 - val_accuracy: 0.4554\n",
            "Epoch 24/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3964 - accuracy: 0.3905 - val_loss: 1.3881 - val_accuracy: 0.3762\n",
            "Epoch 25/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3902 - accuracy: 0.3949 - val_loss: 1.3574 - val_accuracy: 0.4455\n",
            "Epoch 26/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3631 - accuracy: 0.4347 - val_loss: 1.3683 - val_accuracy: 0.4554\n",
            "Epoch 27/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3945 - accuracy: 0.3805 - val_loss: 1.4795 - val_accuracy: 0.3465\n",
            "Epoch 28/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4747 - accuracy: 0.3573 - val_loss: 1.4487 - val_accuracy: 0.3267\n",
            "Epoch 29/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4322 - accuracy: 0.3496 - val_loss: 1.3822 - val_accuracy: 0.4158\n",
            "Epoch 30/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3733 - accuracy: 0.4237 - val_loss: 1.3026 - val_accuracy: 0.4851\n",
            "Epoch 31/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3369 - accuracy: 0.4513 - val_loss: 1.3545 - val_accuracy: 0.3960\n",
            "Epoch 32/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3422 - accuracy: 0.4436 - val_loss: 1.2784 - val_accuracy: 0.4455\n",
            "Epoch 33/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2890 - accuracy: 0.4569 - val_loss: 1.2900 - val_accuracy: 0.4752\n",
            "Epoch 34/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3011 - accuracy: 0.4447 - val_loss: 1.3408 - val_accuracy: 0.5050\n",
            "Epoch 35/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3767 - accuracy: 0.4204 - val_loss: 1.2632 - val_accuracy: 0.4554\n",
            "Epoch 36/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2938 - accuracy: 0.4934 - val_loss: 1.4355 - val_accuracy: 0.3366\n",
            "Epoch 37/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3114 - accuracy: 0.4469 - val_loss: 1.3162 - val_accuracy: 0.4752\n",
            "Epoch 38/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3011 - accuracy: 0.4535 - val_loss: 1.2582 - val_accuracy: 0.5149\n",
            "Epoch 39/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3002 - accuracy: 0.4646 - val_loss: 1.3397 - val_accuracy: 0.4554\n",
            "Epoch 40/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2725 - accuracy: 0.4735 - val_loss: 1.3391 - val_accuracy: 0.4158\n",
            "Epoch 41/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.3279 - accuracy: 0.4237 - val_loss: 1.3034 - val_accuracy: 0.4554\n",
            "Epoch 42/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3421 - accuracy: 0.3993 - val_loss: 1.2709 - val_accuracy: 0.5149\n",
            "Epoch 43/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2956 - accuracy: 0.4746 - val_loss: 1.2726 - val_accuracy: 0.4455\n",
            "Epoch 44/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2587 - accuracy: 0.5044 - val_loss: 1.2558 - val_accuracy: 0.4851\n",
            "Epoch 45/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2392 - accuracy: 0.4978 - val_loss: 1.2187 - val_accuracy: 0.5347\n",
            "Epoch 46/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2299 - accuracy: 0.5088 - val_loss: 1.2349 - val_accuracy: 0.5050\n",
            "Epoch 47/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2677 - accuracy: 0.4668 - val_loss: 1.2440 - val_accuracy: 0.5248\n",
            "Epoch 48/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2504 - accuracy: 0.4823 - val_loss: 1.2452 - val_accuracy: 0.5050\n",
            "Epoch 49/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2189 - accuracy: 0.5044 - val_loss: 1.2304 - val_accuracy: 0.4752\n",
            "Epoch 50/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2237 - accuracy: 0.4967 - val_loss: 1.2098 - val_accuracy: 0.4653\n",
            "Epoch 51/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2988 - accuracy: 0.4480 - val_loss: 1.2769 - val_accuracy: 0.4752\n",
            "Epoch 52/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2341 - accuracy: 0.4956 - val_loss: 1.2298 - val_accuracy: 0.4554\n",
            "Epoch 53/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2764 - accuracy: 0.4646 - val_loss: 1.2066 - val_accuracy: 0.5347\n",
            "Epoch 54/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2352 - accuracy: 0.4900 - val_loss: 1.4114 - val_accuracy: 0.3663\n",
            "Epoch 55/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3811 - accuracy: 0.4170 - val_loss: 1.3963 - val_accuracy: 0.4455\n",
            "Epoch 56/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3327 - accuracy: 0.4358 - val_loss: 1.2632 - val_accuracy: 0.4257\n",
            "Epoch 57/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3059 - accuracy: 0.4403 - val_loss: 1.2713 - val_accuracy: 0.4158\n",
            "Epoch 58/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2516 - accuracy: 0.4779 - val_loss: 1.2334 - val_accuracy: 0.4554\n",
            "Epoch 59/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2276 - accuracy: 0.4790 - val_loss: 1.2484 - val_accuracy: 0.4851\n",
            "Epoch 60/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2535 - accuracy: 0.4602 - val_loss: 1.1931 - val_accuracy: 0.5248\n",
            "Epoch 61/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2579 - accuracy: 0.4679 - val_loss: 1.2474 - val_accuracy: 0.5050\n",
            "Epoch 62/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2120 - accuracy: 0.4856 - val_loss: 1.2034 - val_accuracy: 0.5149\n",
            "Epoch 63/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1938 - accuracy: 0.5044 - val_loss: 1.1953 - val_accuracy: 0.4752\n",
            "Epoch 64/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2085 - accuracy: 0.4768 - val_loss: 1.1781 - val_accuracy: 0.5347\n",
            "Epoch 65/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2065 - accuracy: 0.5033 - val_loss: 1.1629 - val_accuracy: 0.4752\n",
            "Epoch 66/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1767 - accuracy: 0.5111 - val_loss: 1.1819 - val_accuracy: 0.4851\n",
            "Epoch 67/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2284 - accuracy: 0.5022 - val_loss: 1.1866 - val_accuracy: 0.4851\n",
            "Epoch 68/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1815 - accuracy: 0.5066 - val_loss: 1.2111 - val_accuracy: 0.4653\n",
            "Epoch 69/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2200 - accuracy: 0.4690 - val_loss: 1.1760 - val_accuracy: 0.4950\n",
            "Epoch 70/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2284 - accuracy: 0.4735 - val_loss: 1.2300 - val_accuracy: 0.5347\n",
            "Epoch 71/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1848 - accuracy: 0.4967 - val_loss: 1.1783 - val_accuracy: 0.5446\n",
            "Epoch 72/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1630 - accuracy: 0.5310 - val_loss: 1.1440 - val_accuracy: 0.5248\n",
            "Epoch 73/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1539 - accuracy: 0.5442 - val_loss: 1.1337 - val_accuracy: 0.5446\n",
            "Epoch 74/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1590 - accuracy: 0.5332 - val_loss: 1.2047 - val_accuracy: 0.4851\n",
            "Epoch 75/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2044 - accuracy: 0.4978 - val_loss: 1.1566 - val_accuracy: 0.5644\n",
            "Epoch 76/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1845 - accuracy: 0.4989 - val_loss: 1.1614 - val_accuracy: 0.5248\n",
            "Epoch 77/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1922 - accuracy: 0.5044 - val_loss: 1.2804 - val_accuracy: 0.4752\n",
            "Epoch 78/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2323 - accuracy: 0.4580 - val_loss: 1.1878 - val_accuracy: 0.5743\n",
            "Epoch 79/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2063 - accuracy: 0.4768 - val_loss: 1.1878 - val_accuracy: 0.4950\n",
            "Epoch 80/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2441 - accuracy: 0.5077 - val_loss: 1.1407 - val_accuracy: 0.5248\n",
            "Epoch 81/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1610 - accuracy: 0.5133 - val_loss: 1.1416 - val_accuracy: 0.5149\n",
            "Epoch 82/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1855 - accuracy: 0.5111 - val_loss: 1.1190 - val_accuracy: 0.5743\n",
            "Epoch 83/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1703 - accuracy: 0.5155 - val_loss: 1.1088 - val_accuracy: 0.4851\n",
            "Epoch 84/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1598 - accuracy: 0.5321 - val_loss: 1.1773 - val_accuracy: 0.4653\n",
            "Epoch 85/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2034 - accuracy: 0.4900 - val_loss: 1.1525 - val_accuracy: 0.4653\n",
            "Epoch 86/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2236 - accuracy: 0.4657 - val_loss: 1.2340 - val_accuracy: 0.5050\n",
            "Epoch 87/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2096 - accuracy: 0.4912 - val_loss: 1.1019 - val_accuracy: 0.5545\n",
            "Epoch 88/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1637 - accuracy: 0.5310 - val_loss: 1.0858 - val_accuracy: 0.6139\n",
            "Epoch 89/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1433 - accuracy: 0.5442 - val_loss: 1.1517 - val_accuracy: 0.5644\n",
            "Epoch 90/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1433 - accuracy: 0.5597 - val_loss: 1.1151 - val_accuracy: 0.5446\n",
            "Epoch 91/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1941 - accuracy: 0.5000 - val_loss: 1.2043 - val_accuracy: 0.5347\n",
            "Epoch 92/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1507 - accuracy: 0.5310 - val_loss: 1.1432 - val_accuracy: 0.5446\n",
            "Epoch 93/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1521 - accuracy: 0.5210 - val_loss: 1.1583 - val_accuracy: 0.4851\n",
            "Epoch 94/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1273 - accuracy: 0.5343 - val_loss: 1.0929 - val_accuracy: 0.4950\n",
            "Epoch 95/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0900 - accuracy: 0.5808 - val_loss: 1.0653 - val_accuracy: 0.5644\n",
            "Epoch 96/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1195 - accuracy: 0.5321 - val_loss: 1.0751 - val_accuracy: 0.5545\n",
            "Epoch 97/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0781 - accuracy: 0.5719 - val_loss: 1.1230 - val_accuracy: 0.5941\n",
            "Epoch 98/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1211 - accuracy: 0.5376 - val_loss: 1.0881 - val_accuracy: 0.5545\n",
            "Epoch 99/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1378 - accuracy: 0.5254 - val_loss: 1.1367 - val_accuracy: 0.5446\n",
            "Epoch 100/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0833 - accuracy: 0.5730 - val_loss: 1.0534 - val_accuracy: 0.6238\n",
            "Epoch 101/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1001 - accuracy: 0.5531 - val_loss: 1.0352 - val_accuracy: 0.5941\n",
            "Epoch 102/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0701 - accuracy: 0.5730 - val_loss: 1.0736 - val_accuracy: 0.6139\n",
            "Epoch 103/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0953 - accuracy: 0.5454 - val_loss: 1.1157 - val_accuracy: 0.5842\n",
            "Epoch 104/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1546 - accuracy: 0.5431 - val_loss: 1.0856 - val_accuracy: 0.5941\n",
            "Epoch 105/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1700 - accuracy: 0.5088 - val_loss: 1.0653 - val_accuracy: 0.5347\n",
            "Epoch 106/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1032 - accuracy: 0.5619 - val_loss: 1.0778 - val_accuracy: 0.5248\n",
            "Epoch 107/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0880 - accuracy: 0.5819 - val_loss: 1.0529 - val_accuracy: 0.5545\n",
            "Epoch 108/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0967 - accuracy: 0.5420 - val_loss: 1.0329 - val_accuracy: 0.5644\n",
            "Epoch 109/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0536 - accuracy: 0.5951 - val_loss: 1.1691 - val_accuracy: 0.5050\n",
            "Epoch 110/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1915 - accuracy: 0.5210 - val_loss: 1.0203 - val_accuracy: 0.6238\n",
            "Epoch 111/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0693 - accuracy: 0.5796 - val_loss: 1.0758 - val_accuracy: 0.5347\n",
            "Epoch 112/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0637 - accuracy: 0.5852 - val_loss: 1.0169 - val_accuracy: 0.5842\n",
            "Epoch 113/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0833 - accuracy: 0.5619 - val_loss: 1.0593 - val_accuracy: 0.5446\n",
            "Epoch 114/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1036 - accuracy: 0.5431 - val_loss: 1.0171 - val_accuracy: 0.6238\n",
            "Epoch 115/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0507 - accuracy: 0.5730 - val_loss: 1.1182 - val_accuracy: 0.5149\n",
            "Epoch 116/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0569 - accuracy: 0.5730 - val_loss: 1.0085 - val_accuracy: 0.6040\n",
            "Epoch 117/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0397 - accuracy: 0.5962 - val_loss: 1.0735 - val_accuracy: 0.5149\n",
            "Epoch 118/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0758 - accuracy: 0.5476 - val_loss: 0.9735 - val_accuracy: 0.6238\n",
            "Epoch 119/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0311 - accuracy: 0.5763 - val_loss: 1.0399 - val_accuracy: 0.5149\n",
            "Epoch 120/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0348 - accuracy: 0.5708 - val_loss: 1.0511 - val_accuracy: 0.5347\n",
            "Epoch 121/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0549 - accuracy: 0.5642 - val_loss: 1.0665 - val_accuracy: 0.5347\n",
            "Epoch 122/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0471 - accuracy: 0.5730 - val_loss: 0.9973 - val_accuracy: 0.5446\n",
            "Epoch 123/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0295 - accuracy: 0.5996 - val_loss: 0.9679 - val_accuracy: 0.6436\n",
            "Epoch 124/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0802 - accuracy: 0.5774 - val_loss: 0.9867 - val_accuracy: 0.5842\n",
            "Epoch 125/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0539 - accuracy: 0.5752 - val_loss: 0.9915 - val_accuracy: 0.6040\n",
            "Epoch 126/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0473 - accuracy: 0.5763 - val_loss: 1.0131 - val_accuracy: 0.6139\n",
            "Epoch 127/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0033 - accuracy: 0.6162 - val_loss: 0.9986 - val_accuracy: 0.6238\n",
            "Epoch 128/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9978 - accuracy: 0.6084 - val_loss: 1.0369 - val_accuracy: 0.6238\n",
            "Epoch 129/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9973 - accuracy: 0.6051 - val_loss: 0.9473 - val_accuracy: 0.6337\n",
            "Epoch 130/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9793 - accuracy: 0.6073 - val_loss: 0.9288 - val_accuracy: 0.6040\n",
            "Epoch 131/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9757 - accuracy: 0.6206 - val_loss: 0.9936 - val_accuracy: 0.6139\n",
            "Epoch 132/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0058 - accuracy: 0.5929 - val_loss: 1.0907 - val_accuracy: 0.5842\n",
            "Epoch 133/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9930 - accuracy: 0.6095 - val_loss: 0.9940 - val_accuracy: 0.5644\n",
            "Epoch 134/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0098 - accuracy: 0.5719 - val_loss: 1.1238 - val_accuracy: 0.5149\n",
            "Epoch 135/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0844 - accuracy: 0.5476 - val_loss: 1.0002 - val_accuracy: 0.5446\n",
            "Epoch 136/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0026 - accuracy: 0.5996 - val_loss: 0.9465 - val_accuracy: 0.6337\n",
            "Epoch 137/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9557 - accuracy: 0.6283 - val_loss: 0.9605 - val_accuracy: 0.6436\n",
            "Epoch 138/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9585 - accuracy: 0.6195 - val_loss: 1.0422 - val_accuracy: 0.5347\n",
            "Epoch 139/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0125 - accuracy: 0.5841 - val_loss: 0.9817 - val_accuracy: 0.6535\n",
            "Epoch 140/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9947 - accuracy: 0.5951 - val_loss: 0.9075 - val_accuracy: 0.6436\n",
            "Epoch 141/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9619 - accuracy: 0.6294 - val_loss: 1.1268 - val_accuracy: 0.4950\n",
            "Epoch 142/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1171 - accuracy: 0.5321 - val_loss: 0.9443 - val_accuracy: 0.5941\n",
            "Epoch 143/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0210 - accuracy: 0.5918 - val_loss: 0.8994 - val_accuracy: 0.6238\n",
            "Epoch 144/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9685 - accuracy: 0.6239 - val_loss: 0.9795 - val_accuracy: 0.6436\n",
            "Epoch 145/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9757 - accuracy: 0.6018 - val_loss: 1.0346 - val_accuracy: 0.5545\n",
            "Epoch 146/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0617 - accuracy: 0.5675 - val_loss: 0.9487 - val_accuracy: 0.6238\n",
            "Epoch 147/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0298 - accuracy: 0.5564 - val_loss: 1.0927 - val_accuracy: 0.5149\n",
            "Epoch 148/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0712 - accuracy: 0.5564 - val_loss: 1.0455 - val_accuracy: 0.5446\n",
            "Epoch 149/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0146 - accuracy: 0.5796 - val_loss: 0.9186 - val_accuracy: 0.6139\n",
            "Epoch 150/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9792 - accuracy: 0.6139 - val_loss: 0.8969 - val_accuracy: 0.6337\n",
            "Epoch 151/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9321 - accuracy: 0.6327 - val_loss: 0.8846 - val_accuracy: 0.6139\n",
            "Epoch 152/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9137 - accuracy: 0.6482 - val_loss: 1.0169 - val_accuracy: 0.6238\n",
            "Epoch 153/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9580 - accuracy: 0.6128 - val_loss: 0.9218 - val_accuracy: 0.6337\n",
            "Epoch 154/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9254 - accuracy: 0.6383 - val_loss: 0.9756 - val_accuracy: 0.6040\n",
            "Epoch 155/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9604 - accuracy: 0.6261 - val_loss: 1.0186 - val_accuracy: 0.5842\n",
            "Epoch 156/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9808 - accuracy: 0.6106 - val_loss: 0.9880 - val_accuracy: 0.6436\n",
            "Epoch 157/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9927 - accuracy: 0.6106 - val_loss: 1.0442 - val_accuracy: 0.5842\n",
            "Epoch 158/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9888 - accuracy: 0.6095 - val_loss: 0.9848 - val_accuracy: 0.6040\n",
            "Epoch 159/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9980 - accuracy: 0.5996 - val_loss: 0.8553 - val_accuracy: 0.6337\n",
            "Epoch 160/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9442 - accuracy: 0.6316 - val_loss: 0.8735 - val_accuracy: 0.6238\n",
            "Epoch 161/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8971 - accuracy: 0.6527 - val_loss: 0.9414 - val_accuracy: 0.5941\n",
            "Epoch 162/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9419 - accuracy: 0.6239 - val_loss: 1.0043 - val_accuracy: 0.5941\n",
            "Epoch 163/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0027 - accuracy: 0.5819 - val_loss: 0.9599 - val_accuracy: 0.5743\n",
            "Epoch 164/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9416 - accuracy: 0.6084 - val_loss: 0.9055 - val_accuracy: 0.6337\n",
            "Epoch 165/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9151 - accuracy: 0.6394 - val_loss: 0.9211 - val_accuracy: 0.6040\n",
            "Epoch 166/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9692 - accuracy: 0.6195 - val_loss: 0.8933 - val_accuracy: 0.6139\n",
            "Epoch 167/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9032 - accuracy: 0.6361 - val_loss: 0.8211 - val_accuracy: 0.6634\n",
            "Epoch 168/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8691 - accuracy: 0.6648 - val_loss: 0.8907 - val_accuracy: 0.6040\n",
            "Epoch 169/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8893 - accuracy: 0.6471 - val_loss: 0.8561 - val_accuracy: 0.6436\n",
            "Epoch 170/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8933 - accuracy: 0.6438 - val_loss: 0.8170 - val_accuracy: 0.6634\n",
            "Epoch 171/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8893 - accuracy: 0.6438 - val_loss: 0.8215 - val_accuracy: 0.6832\n",
            "Epoch 172/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8509 - accuracy: 0.6881 - val_loss: 0.8191 - val_accuracy: 0.6832\n",
            "Epoch 173/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8664 - accuracy: 0.6571 - val_loss: 0.8295 - val_accuracy: 0.6931\n",
            "Epoch 174/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8462 - accuracy: 0.6781 - val_loss: 0.8456 - val_accuracy: 0.6535\n",
            "Epoch 175/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9016 - accuracy: 0.6416 - val_loss: 1.0965 - val_accuracy: 0.5743\n",
            "Epoch 176/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0146 - accuracy: 0.5885 - val_loss: 0.8299 - val_accuracy: 0.6931\n",
            "Epoch 177/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9489 - accuracy: 0.6217 - val_loss: 0.9180 - val_accuracy: 0.6238\n",
            "Epoch 178/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9152 - accuracy: 0.6272 - val_loss: 0.8725 - val_accuracy: 0.6436\n",
            "Epoch 179/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8914 - accuracy: 0.6217 - val_loss: 0.8904 - val_accuracy: 0.6733\n",
            "Epoch 180/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8517 - accuracy: 0.6770 - val_loss: 1.0463 - val_accuracy: 0.5941\n",
            "Epoch 181/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9415 - accuracy: 0.6427 - val_loss: 0.7862 - val_accuracy: 0.7426\n",
            "Epoch 182/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8794 - accuracy: 0.6637 - val_loss: 0.9152 - val_accuracy: 0.6040\n",
            "Epoch 183/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8982 - accuracy: 0.6427 - val_loss: 0.8036 - val_accuracy: 0.6733\n",
            "Epoch 184/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8287 - accuracy: 0.6892 - val_loss: 0.7756 - val_accuracy: 0.7030\n",
            "Epoch 185/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8359 - accuracy: 0.6825 - val_loss: 0.8157 - val_accuracy: 0.6931\n",
            "Epoch 186/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9095 - accuracy: 0.6294 - val_loss: 0.7671 - val_accuracy: 0.7426\n",
            "Epoch 187/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8765 - accuracy: 0.6460 - val_loss: 0.8471 - val_accuracy: 0.6436\n",
            "Epoch 188/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8395 - accuracy: 0.6803 - val_loss: 0.9678 - val_accuracy: 0.6139\n",
            "Epoch 189/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9340 - accuracy: 0.6128 - val_loss: 0.8158 - val_accuracy: 0.6535\n",
            "Epoch 190/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8373 - accuracy: 0.6715 - val_loss: 1.2469 - val_accuracy: 0.4356\n",
            "Epoch 191/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1580 - accuracy: 0.5243 - val_loss: 0.8684 - val_accuracy: 0.6733\n",
            "Epoch 192/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1264 - accuracy: 0.5420 - val_loss: 0.9558 - val_accuracy: 0.6238\n",
            "Epoch 193/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0240 - accuracy: 0.5608 - val_loss: 1.0328 - val_accuracy: 0.6238\n",
            "Epoch 194/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9227 - accuracy: 0.6272 - val_loss: 1.0229 - val_accuracy: 0.5941\n",
            "Epoch 195/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9002 - accuracy: 0.6128 - val_loss: 0.9300 - val_accuracy: 0.6040\n",
            "Epoch 196/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9133 - accuracy: 0.6350 - val_loss: 0.7964 - val_accuracy: 0.6733\n",
            "Epoch 197/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8569 - accuracy: 0.6781 - val_loss: 0.9039 - val_accuracy: 0.6040\n",
            "Epoch 198/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8993 - accuracy: 0.6527 - val_loss: 0.7976 - val_accuracy: 0.6931\n",
            "Epoch 199/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8405 - accuracy: 0.6715 - val_loss: 0.8410 - val_accuracy: 0.6238\n",
            "Epoch 200/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8417 - accuracy: 0.6715 - val_loss: 0.9280 - val_accuracy: 0.5644\n",
            "Epoch 201/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9247 - accuracy: 0.6217 - val_loss: 0.9227 - val_accuracy: 0.5743\n",
            "Epoch 202/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9315 - accuracy: 0.6195 - val_loss: 0.9266 - val_accuracy: 0.5842\n",
            "Epoch 203/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9590 - accuracy: 0.6095 - val_loss: 0.9267 - val_accuracy: 0.6832\n",
            "Epoch 204/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9481 - accuracy: 0.6128 - val_loss: 0.9715 - val_accuracy: 0.6337\n",
            "Epoch 205/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9165 - accuracy: 0.6173 - val_loss: 0.8081 - val_accuracy: 0.6931\n",
            "Epoch 206/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8431 - accuracy: 0.6803 - val_loss: 0.8266 - val_accuracy: 0.6634\n",
            "Epoch 207/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8141 - accuracy: 0.6925 - val_loss: 0.7626 - val_accuracy: 0.6832\n",
            "Epoch 208/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8252 - accuracy: 0.6847 - val_loss: 0.7573 - val_accuracy: 0.7426\n",
            "Epoch 209/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8053 - accuracy: 0.6980 - val_loss: 0.7815 - val_accuracy: 0.7327\n",
            "Epoch 210/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8111 - accuracy: 0.6980 - val_loss: 0.9022 - val_accuracy: 0.6535\n",
            "Epoch 211/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9291 - accuracy: 0.6051 - val_loss: 0.8945 - val_accuracy: 0.5941\n",
            "Epoch 212/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8368 - accuracy: 0.6593 - val_loss: 0.9591 - val_accuracy: 0.5347\n",
            "Epoch 213/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8884 - accuracy: 0.6327 - val_loss: 0.7251 - val_accuracy: 0.7228\n",
            "Epoch 214/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8315 - accuracy: 0.6704 - val_loss: 0.8860 - val_accuracy: 0.6634\n",
            "Epoch 215/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8179 - accuracy: 0.6781 - val_loss: 0.7515 - val_accuracy: 0.7624\n",
            "Epoch 216/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7876 - accuracy: 0.6991 - val_loss: 0.7949 - val_accuracy: 0.6535\n",
            "Epoch 217/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8260 - accuracy: 0.6836 - val_loss: 0.7661 - val_accuracy: 0.6832\n",
            "Epoch 218/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8157 - accuracy: 0.6726 - val_loss: 0.8061 - val_accuracy: 0.7129\n",
            "Epoch 219/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8462 - accuracy: 0.6615 - val_loss: 0.7178 - val_accuracy: 0.7624\n",
            "Epoch 220/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8015 - accuracy: 0.6936 - val_loss: 0.7392 - val_accuracy: 0.7228\n",
            "Epoch 221/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7603 - accuracy: 0.7146 - val_loss: 0.7045 - val_accuracy: 0.7327\n",
            "Epoch 222/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7643 - accuracy: 0.7146 - val_loss: 0.7574 - val_accuracy: 0.6931\n",
            "Epoch 223/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8151 - accuracy: 0.6715 - val_loss: 0.8206 - val_accuracy: 0.6238\n",
            "Epoch 224/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7849 - accuracy: 0.6947 - val_loss: 0.7157 - val_accuracy: 0.7723\n",
            "Epoch 225/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7555 - accuracy: 0.7367 - val_loss: 0.8284 - val_accuracy: 0.6634\n",
            "Epoch 226/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.6980 - val_loss: 0.7086 - val_accuracy: 0.7525\n",
            "Epoch 227/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7750 - accuracy: 0.7157 - val_loss: 0.8374 - val_accuracy: 0.6436\n",
            "Epoch 228/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8239 - accuracy: 0.6759 - val_loss: 0.7196 - val_accuracy: 0.7129\n",
            "Epoch 229/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7726 - accuracy: 0.7035 - val_loss: 0.6895 - val_accuracy: 0.7822\n",
            "Epoch 230/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7328 - accuracy: 0.7235 - val_loss: 0.8273 - val_accuracy: 0.6535\n",
            "Epoch 231/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8199 - accuracy: 0.6681 - val_loss: 0.7038 - val_accuracy: 0.7327\n",
            "Epoch 232/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8178 - accuracy: 0.6881 - val_loss: 0.9016 - val_accuracy: 0.6634\n",
            "Epoch 233/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8500 - accuracy: 0.6582 - val_loss: 0.7086 - val_accuracy: 0.7327\n",
            "Epoch 234/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7502 - accuracy: 0.7146 - val_loss: 0.7433 - val_accuracy: 0.7129\n",
            "Epoch 235/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8100 - accuracy: 0.6903 - val_loss: 0.7368 - val_accuracy: 0.6931\n",
            "Epoch 236/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7649 - accuracy: 0.7069 - val_loss: 0.7409 - val_accuracy: 0.6733\n",
            "Epoch 237/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7632 - accuracy: 0.7080 - val_loss: 0.9198 - val_accuracy: 0.6040\n",
            "Epoch 238/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8344 - accuracy: 0.6726 - val_loss: 0.9257 - val_accuracy: 0.7030\n",
            "Epoch 239/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8820 - accuracy: 0.6604 - val_loss: 0.8019 - val_accuracy: 0.7129\n",
            "Epoch 240/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7572 - accuracy: 0.7179 - val_loss: 0.6754 - val_accuracy: 0.7624\n",
            "Epoch 241/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7301 - accuracy: 0.7268 - val_loss: 0.6772 - val_accuracy: 0.7822\n",
            "Epoch 242/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7178 - accuracy: 0.7544 - val_loss: 0.6981 - val_accuracy: 0.7327\n",
            "Epoch 243/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7124 - accuracy: 0.7434 - val_loss: 0.7319 - val_accuracy: 0.7426\n",
            "Epoch 244/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7247 - accuracy: 0.7323 - val_loss: 0.6773 - val_accuracy: 0.7921\n",
            "Epoch 245/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7183 - accuracy: 0.7456 - val_loss: 0.6676 - val_accuracy: 0.8020\n",
            "Epoch 246/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7156 - accuracy: 0.7467 - val_loss: 0.6649 - val_accuracy: 0.7525\n",
            "Epoch 247/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6980 - accuracy: 0.7467 - val_loss: 0.6448 - val_accuracy: 0.7921\n",
            "Epoch 248/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7048 - accuracy: 0.7434 - val_loss: 0.6793 - val_accuracy: 0.7327\n",
            "Epoch 249/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7049 - accuracy: 0.7467 - val_loss: 0.7240 - val_accuracy: 0.6832\n",
            "Epoch 250/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7477 - accuracy: 0.6991 - val_loss: 0.7428 - val_accuracy: 0.7327\n",
            "Epoch 251/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7564 - accuracy: 0.7058 - val_loss: 0.7277 - val_accuracy: 0.6832\n",
            "Epoch 252/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7107 - accuracy: 0.7323 - val_loss: 0.7349 - val_accuracy: 0.6832\n",
            "Epoch 253/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7553 - accuracy: 0.6969 - val_loss: 0.6720 - val_accuracy: 0.7822\n",
            "Epoch 254/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7156 - accuracy: 0.7301 - val_loss: 0.7647 - val_accuracy: 0.6634\n",
            "Epoch 255/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7410 - accuracy: 0.7124 - val_loss: 0.6829 - val_accuracy: 0.7426\n",
            "Epoch 256/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7036 - accuracy: 0.7412 - val_loss: 0.6896 - val_accuracy: 0.7030\n",
            "Epoch 257/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7273 - accuracy: 0.7323 - val_loss: 0.7080 - val_accuracy: 0.7624\n",
            "Epoch 258/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7079 - accuracy: 0.7434 - val_loss: 0.7492 - val_accuracy: 0.6832\n",
            "Epoch 259/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7730 - accuracy: 0.6991 - val_loss: 0.7895 - val_accuracy: 0.6931\n",
            "Epoch 260/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7507 - accuracy: 0.7124 - val_loss: 0.9742 - val_accuracy: 0.6238\n",
            "Epoch 261/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8950 - accuracy: 0.6449 - val_loss: 0.6205 - val_accuracy: 0.7921\n",
            "Epoch 262/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9259 - accuracy: 0.6416 - val_loss: 0.8800 - val_accuracy: 0.6040\n",
            "Epoch 263/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8224 - accuracy: 0.6748 - val_loss: 0.7182 - val_accuracy: 0.7822\n",
            "Epoch 264/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7504 - accuracy: 0.7035 - val_loss: 0.7480 - val_accuracy: 0.6832\n",
            "Epoch 265/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7993 - accuracy: 0.6814 - val_loss: 0.8166 - val_accuracy: 0.6733\n",
            "Epoch 266/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9094 - accuracy: 0.6416 - val_loss: 0.6581 - val_accuracy: 0.7525\n",
            "Epoch 267/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7663 - accuracy: 0.7035 - val_loss: 0.8170 - val_accuracy: 0.6040\n",
            "Epoch 268/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7517 - accuracy: 0.7146 - val_loss: 0.6622 - val_accuracy: 0.7723\n",
            "Epoch 269/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7078 - accuracy: 0.7389 - val_loss: 0.6380 - val_accuracy: 0.7723\n",
            "Epoch 270/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6844 - accuracy: 0.7500 - val_loss: 0.6848 - val_accuracy: 0.7525\n",
            "Epoch 271/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6847 - accuracy: 0.7533 - val_loss: 0.6467 - val_accuracy: 0.8020\n",
            "Epoch 272/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6867 - accuracy: 0.7445 - val_loss: 0.6191 - val_accuracy: 0.7723\n",
            "Epoch 273/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6748 - accuracy: 0.7533 - val_loss: 1.0017 - val_accuracy: 0.5743\n",
            "Epoch 274/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7861 - accuracy: 0.6836 - val_loss: 0.6541 - val_accuracy: 0.7525\n",
            "Epoch 275/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7693 - accuracy: 0.7024 - val_loss: 0.6164 - val_accuracy: 0.7723\n",
            "Epoch 276/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6990 - accuracy: 0.7312 - val_loss: 0.7394 - val_accuracy: 0.7228\n",
            "Epoch 277/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6968 - accuracy: 0.7456 - val_loss: 0.8092 - val_accuracy: 0.6436\n",
            "Epoch 278/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7958 - accuracy: 0.6715 - val_loss: 0.6789 - val_accuracy: 0.7030\n",
            "Epoch 279/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7074 - accuracy: 0.7378 - val_loss: 0.7062 - val_accuracy: 0.7030\n",
            "Epoch 280/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7033 - accuracy: 0.7312 - val_loss: 0.6873 - val_accuracy: 0.8020\n",
            "Epoch 281/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7388 - accuracy: 0.7058 - val_loss: 0.6453 - val_accuracy: 0.7723\n",
            "Epoch 282/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7185 - accuracy: 0.7190 - val_loss: 0.6137 - val_accuracy: 0.7624\n",
            "Epoch 283/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6715 - accuracy: 0.7500 - val_loss: 0.6463 - val_accuracy: 0.7723\n",
            "Epoch 284/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6868 - accuracy: 0.7389 - val_loss: 0.6297 - val_accuracy: 0.7426\n",
            "Epoch 285/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.7153 - accuracy: 0.7201 - val_loss: 0.6301 - val_accuracy: 0.8119\n",
            "Epoch 286/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6970 - accuracy: 0.7522 - val_loss: 0.6735 - val_accuracy: 0.7327\n",
            "Epoch 287/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7041 - accuracy: 0.7312 - val_loss: 0.7880 - val_accuracy: 0.6832\n",
            "Epoch 288/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7393 - accuracy: 0.6969 - val_loss: 0.6160 - val_accuracy: 0.7624\n",
            "Epoch 289/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6674 - accuracy: 0.7644 - val_loss: 0.6134 - val_accuracy: 0.7426\n",
            "Epoch 290/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6614 - accuracy: 0.7566 - val_loss: 0.7731 - val_accuracy: 0.6634\n",
            "Epoch 291/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7345 - accuracy: 0.7024 - val_loss: 0.6389 - val_accuracy: 0.7921\n",
            "Epoch 292/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6976 - accuracy: 0.7323 - val_loss: 0.6146 - val_accuracy: 0.8218\n",
            "Epoch 293/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6453 - accuracy: 0.7699 - val_loss: 0.5950 - val_accuracy: 0.7921\n",
            "Epoch 294/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6511 - accuracy: 0.7611 - val_loss: 0.6058 - val_accuracy: 0.8020\n",
            "Epoch 295/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6441 - accuracy: 0.7655 - val_loss: 0.6998 - val_accuracy: 0.7525\n",
            "Epoch 296/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6705 - accuracy: 0.7445 - val_loss: 0.6230 - val_accuracy: 0.7228\n",
            "Epoch 297/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6424 - accuracy: 0.7854 - val_loss: 0.6154 - val_accuracy: 0.8020\n",
            "Epoch 298/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6394 - accuracy: 0.7688 - val_loss: 0.6017 - val_accuracy: 0.8020\n",
            "Epoch 299/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6422 - accuracy: 0.7699 - val_loss: 0.6585 - val_accuracy: 0.7525\n",
            "Epoch 300/400\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.6637 - accuracy: 0.7456 - val_loss: 0.7169 - val_accuracy: 0.7822\n",
            "Epoch 301/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7114 - accuracy: 0.7201 - val_loss: 1.0469 - val_accuracy: 0.5644\n",
            "Epoch 302/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8948 - accuracy: 0.6283 - val_loss: 0.6142 - val_accuracy: 0.8020\n",
            "Epoch 303/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7243 - accuracy: 0.7223 - val_loss: 0.6344 - val_accuracy: 0.7921\n",
            "Epoch 304/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7123 - accuracy: 0.7279 - val_loss: 0.6185 - val_accuracy: 0.7723\n",
            "Epoch 305/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6750 - accuracy: 0.7378 - val_loss: 0.7792 - val_accuracy: 0.7129\n",
            "Epoch 306/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7563 - accuracy: 0.6969 - val_loss: 0.8632 - val_accuracy: 0.6634\n",
            "Epoch 307/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7035 - accuracy: 0.7334 - val_loss: 0.8125 - val_accuracy: 0.6238\n",
            "Epoch 308/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8292 - accuracy: 0.6593 - val_loss: 1.0236 - val_accuracy: 0.5446\n",
            "Epoch 309/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8860 - accuracy: 0.6416 - val_loss: 1.0229 - val_accuracy: 0.6040\n",
            "Epoch 310/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7597 - accuracy: 0.7124 - val_loss: 0.6625 - val_accuracy: 0.7723\n",
            "Epoch 311/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6662 - accuracy: 0.7577 - val_loss: 0.6154 - val_accuracy: 0.8218\n",
            "Epoch 312/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6432 - accuracy: 0.7721 - val_loss: 0.5905 - val_accuracy: 0.8119\n",
            "Epoch 313/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6100 - accuracy: 0.7765 - val_loss: 0.6619 - val_accuracy: 0.7723\n",
            "Epoch 314/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6218 - accuracy: 0.7699 - val_loss: 0.5802 - val_accuracy: 0.8020\n",
            "Epoch 315/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5957 - accuracy: 0.7909 - val_loss: 0.6614 - val_accuracy: 0.7426\n",
            "Epoch 316/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6371 - accuracy: 0.7611 - val_loss: 0.5787 - val_accuracy: 0.7723\n",
            "Epoch 317/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6278 - accuracy: 0.7677 - val_loss: 0.7988 - val_accuracy: 0.6931\n",
            "Epoch 318/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7221 - accuracy: 0.7035 - val_loss: 0.6319 - val_accuracy: 0.7426\n",
            "Epoch 319/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7558 - accuracy: 0.6991 - val_loss: 0.7994 - val_accuracy: 0.6634\n",
            "Epoch 320/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7049 - accuracy: 0.7168 - val_loss: 0.5842 - val_accuracy: 0.7921\n",
            "Epoch 321/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6484 - accuracy: 0.7511 - val_loss: 0.6445 - val_accuracy: 0.7525\n",
            "Epoch 322/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6232 - accuracy: 0.7743 - val_loss: 0.6428 - val_accuracy: 0.7822\n",
            "Epoch 323/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6483 - accuracy: 0.7666 - val_loss: 0.5800 - val_accuracy: 0.7723\n",
            "Epoch 324/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6673 - accuracy: 0.7423 - val_loss: 0.6615 - val_accuracy: 0.7129\n",
            "Epoch 325/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6447 - accuracy: 0.7500 - val_loss: 0.5876 - val_accuracy: 0.8317\n",
            "Epoch 326/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6099 - accuracy: 0.7821 - val_loss: 0.6047 - val_accuracy: 0.7921\n",
            "Epoch 327/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6246 - accuracy: 0.7633 - val_loss: 0.7308 - val_accuracy: 0.6733\n",
            "Epoch 328/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6609 - accuracy: 0.7445 - val_loss: 0.6502 - val_accuracy: 0.7921\n",
            "Epoch 329/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6479 - accuracy: 0.7600 - val_loss: 0.5759 - val_accuracy: 0.8218\n",
            "Epoch 330/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6313 - accuracy: 0.7677 - val_loss: 0.6676 - val_accuracy: 0.7327\n",
            "Epoch 331/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7032 - accuracy: 0.7345 - val_loss: 0.6676 - val_accuracy: 0.7822\n",
            "Epoch 332/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6558 - accuracy: 0.7511 - val_loss: 0.6307 - val_accuracy: 0.7327\n",
            "Epoch 333/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6411 - accuracy: 0.7577 - val_loss: 0.6602 - val_accuracy: 0.7624\n",
            "Epoch 334/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6352 - accuracy: 0.7777 - val_loss: 0.6249 - val_accuracy: 0.7822\n",
            "Epoch 335/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6120 - accuracy: 0.7777 - val_loss: 0.6254 - val_accuracy: 0.7228\n",
            "Epoch 336/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6064 - accuracy: 0.7699 - val_loss: 0.6476 - val_accuracy: 0.7723\n",
            "Epoch 337/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6621 - accuracy: 0.7456 - val_loss: 0.6141 - val_accuracy: 0.7525\n",
            "Epoch 338/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6913 - accuracy: 0.7400 - val_loss: 0.6019 - val_accuracy: 0.7624\n",
            "Epoch 339/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6995 - accuracy: 0.7312 - val_loss: 1.2697 - val_accuracy: 0.4554\n",
            "Epoch 340/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8094 - accuracy: 0.6604 - val_loss: 0.6130 - val_accuracy: 0.7525\n",
            "Epoch 341/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6863 - accuracy: 0.7445 - val_loss: 0.7019 - val_accuracy: 0.6931\n",
            "Epoch 342/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6555 - accuracy: 0.7423 - val_loss: 0.6585 - val_accuracy: 0.7921\n",
            "Epoch 343/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6292 - accuracy: 0.7754 - val_loss: 0.6104 - val_accuracy: 0.7525\n",
            "Epoch 344/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6006 - accuracy: 0.7788 - val_loss: 0.6355 - val_accuracy: 0.7327\n",
            "Epoch 345/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6209 - accuracy: 0.7688 - val_loss: 0.5794 - val_accuracy: 0.8218\n",
            "Epoch 346/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5653 - accuracy: 0.7909 - val_loss: 0.6394 - val_accuracy: 0.7723\n",
            "Epoch 347/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6399 - accuracy: 0.7611 - val_loss: 0.7382 - val_accuracy: 0.6535\n",
            "Epoch 348/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7118 - accuracy: 0.7190 - val_loss: 0.5442 - val_accuracy: 0.8218\n",
            "Epoch 349/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6238 - accuracy: 0.7699 - val_loss: 0.5570 - val_accuracy: 0.8119\n",
            "Epoch 350/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6032 - accuracy: 0.7765 - val_loss: 0.5718 - val_accuracy: 0.7822\n",
            "Epoch 351/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5998 - accuracy: 0.7732 - val_loss: 0.6587 - val_accuracy: 0.7525\n",
            "Epoch 352/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6025 - accuracy: 0.7788 - val_loss: 0.5958 - val_accuracy: 0.7327\n",
            "Epoch 353/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5945 - accuracy: 0.7754 - val_loss: 0.6163 - val_accuracy: 0.7723\n",
            "Epoch 354/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6229 - accuracy: 0.7577 - val_loss: 0.5855 - val_accuracy: 0.7525\n",
            "Epoch 355/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.7157 - val_loss: 0.5615 - val_accuracy: 0.7822\n",
            "Epoch 356/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6744 - accuracy: 0.7522 - val_loss: 0.5702 - val_accuracy: 0.7921\n",
            "Epoch 357/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6482 - accuracy: 0.7655 - val_loss: 0.6764 - val_accuracy: 0.7426\n",
            "Epoch 358/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.7821 - val_loss: 0.6323 - val_accuracy: 0.7822\n",
            "Epoch 359/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6642 - accuracy: 0.7500 - val_loss: 0.5690 - val_accuracy: 0.8020\n",
            "Epoch 360/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5723 - accuracy: 0.7976 - val_loss: 0.6703 - val_accuracy: 0.7030\n",
            "Epoch 361/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6279 - accuracy: 0.7566 - val_loss: 0.5842 - val_accuracy: 0.7921\n",
            "Epoch 362/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5798 - accuracy: 0.7954 - val_loss: 0.5429 - val_accuracy: 0.8119\n",
            "Epoch 363/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5631 - accuracy: 0.7954 - val_loss: 0.5892 - val_accuracy: 0.8020\n",
            "Epoch 364/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6064 - accuracy: 0.7655 - val_loss: 0.6022 - val_accuracy: 0.7822\n",
            "Epoch 365/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5779 - accuracy: 0.7954 - val_loss: 1.0198 - val_accuracy: 0.5545\n",
            "Epoch 366/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8225 - accuracy: 0.6637 - val_loss: 0.6462 - val_accuracy: 0.7426\n",
            "Epoch 367/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7062 - accuracy: 0.7223 - val_loss: 0.6767 - val_accuracy: 0.7723\n",
            "Epoch 368/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6341 - accuracy: 0.7434 - val_loss: 0.6700 - val_accuracy: 0.7228\n",
            "Epoch 369/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6767 - accuracy: 0.7356 - val_loss: 0.5761 - val_accuracy: 0.8119\n",
            "Epoch 370/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7226 - accuracy: 0.7113 - val_loss: 0.7955 - val_accuracy: 0.6535\n",
            "Epoch 371/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6676 - accuracy: 0.7423 - val_loss: 0.5569 - val_accuracy: 0.8020\n",
            "Epoch 372/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6038 - accuracy: 0.7699 - val_loss: 0.5477 - val_accuracy: 0.8020\n",
            "Epoch 373/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5525 - accuracy: 0.8042 - val_loss: 0.5760 - val_accuracy: 0.8218\n",
            "Epoch 374/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5602 - accuracy: 0.8042 - val_loss: 0.6339 - val_accuracy: 0.7822\n",
            "Epoch 375/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5713 - accuracy: 0.7920 - val_loss: 0.6125 - val_accuracy: 0.7624\n",
            "Epoch 376/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5996 - accuracy: 0.7788 - val_loss: 0.5454 - val_accuracy: 0.8020\n",
            "Epoch 377/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5411 - accuracy: 0.8119 - val_loss: 0.5587 - val_accuracy: 0.8317\n",
            "Epoch 378/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5409 - accuracy: 0.8086 - val_loss: 0.5195 - val_accuracy: 0.8218\n",
            "Epoch 379/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5526 - accuracy: 0.7887 - val_loss: 0.5980 - val_accuracy: 0.7327\n",
            "Epoch 380/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6521 - accuracy: 0.7566 - val_loss: 0.6675 - val_accuracy: 0.7525\n",
            "Epoch 381/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6686 - accuracy: 0.7168 - val_loss: 0.6545 - val_accuracy: 0.7228\n",
            "Epoch 382/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6173 - accuracy: 0.7622 - val_loss: 0.5365 - val_accuracy: 0.7921\n",
            "Epoch 383/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5247 - accuracy: 0.8097 - val_loss: 0.4934 - val_accuracy: 0.8317\n",
            "Epoch 384/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5103 - accuracy: 0.8208 - val_loss: 0.5238 - val_accuracy: 0.8317\n",
            "Epoch 385/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5463 - accuracy: 0.8064 - val_loss: 0.5063 - val_accuracy: 0.8218\n",
            "Epoch 386/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5419 - accuracy: 0.8131 - val_loss: 0.5319 - val_accuracy: 0.8218\n",
            "Epoch 387/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5463 - accuracy: 0.8020 - val_loss: 0.5297 - val_accuracy: 0.8020\n",
            "Epoch 388/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5427 - accuracy: 0.8053 - val_loss: 0.6503 - val_accuracy: 0.7921\n",
            "Epoch 389/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5696 - accuracy: 0.7810 - val_loss: 0.5061 - val_accuracy: 0.8119\n",
            "Epoch 390/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5692 - accuracy: 0.7898 - val_loss: 0.5365 - val_accuracy: 0.8317\n",
            "Epoch 391/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5496 - accuracy: 0.7942 - val_loss: 0.7285 - val_accuracy: 0.7228\n",
            "Epoch 392/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5734 - accuracy: 0.7788 - val_loss: 0.5660 - val_accuracy: 0.8119\n",
            "Epoch 393/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5429 - accuracy: 0.8131 - val_loss: 0.6210 - val_accuracy: 0.7921\n",
            "Epoch 394/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5824 - accuracy: 0.7777 - val_loss: 0.5705 - val_accuracy: 0.7525\n",
            "Epoch 395/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5525 - accuracy: 0.7954 - val_loss: 0.4954 - val_accuracy: 0.8317\n",
            "Epoch 396/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.8119 - val_loss: 0.5261 - val_accuracy: 0.8317\n",
            "Epoch 397/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5142 - accuracy: 0.8119 - val_loss: 0.6951 - val_accuracy: 0.7525\n",
            "Epoch 398/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6293 - accuracy: 0.7611 - val_loss: 0.5141 - val_accuracy: 0.8119\n",
            "Epoch 399/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5676 - accuracy: 0.7854 - val_loss: 0.4882 - val_accuracy: 0.8218\n",
            "Epoch 400/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5068 - accuracy: 0.8263 - val_loss: 0.5305 - val_accuracy: 0.7921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd5ae44f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIMgsBsXCm--"
      },
      "source": [
        "Теперь оценим точность многослойной:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeoSRpGwCpAF",
        "outputId": "12c0afff-d6a8-4d9f-e206-eff968e482f0"
      },
      "source": [
        "\n",
        "\n",
        "score = model2.evaluate(x_test.reshape(int(1500*0.33),1024), y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7627102732658386\n",
            "Test accuracy: 0.7010101079940796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjscbiyLEJcI"
      },
      "source": [
        "Теперь поработаем с однослойной сетью. Потренируем ее:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmG1uNWREPL4",
        "outputId": "b5e9e90e-f583-4659-80c3-ddc12ac1a46b"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 400\n",
        "\n",
        "model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "x_train1 = x_train.reshape(int(1500*0.67),1024)\n",
        "model3.fit(x_train1, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "8/8 [==============================] - 1s 29ms/step - loss: 2.0194 - accuracy: 0.2035 - val_loss: 1.6483 - val_accuracy: 0.2871\n",
            "Epoch 2/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6886 - accuracy: 0.2235 - val_loss: 1.6280 - val_accuracy: 0.1881\n",
            "Epoch 3/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6328 - accuracy: 0.1947 - val_loss: 1.5992 - val_accuracy: 0.2079\n",
            "Epoch 4/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6022 - accuracy: 0.2367 - val_loss: 1.5877 - val_accuracy: 0.2673\n",
            "Epoch 5/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5929 - accuracy: 0.2577 - val_loss: 1.5747 - val_accuracy: 0.2475\n",
            "Epoch 6/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5815 - accuracy: 0.2666 - val_loss: 1.5611 - val_accuracy: 0.4257\n",
            "Epoch 7/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5816 - accuracy: 0.2412 - val_loss: 1.5703 - val_accuracy: 0.2178\n",
            "Epoch 8/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5798 - accuracy: 0.2743 - val_loss: 1.5603 - val_accuracy: 0.3663\n",
            "Epoch 9/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5856 - accuracy: 0.2721 - val_loss: 1.5611 - val_accuracy: 0.3168\n",
            "Epoch 10/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5755 - accuracy: 0.3086 - val_loss: 1.5453 - val_accuracy: 0.4257\n",
            "Epoch 11/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5563 - accuracy: 0.3385 - val_loss: 1.5442 - val_accuracy: 0.3960\n",
            "Epoch 12/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5514 - accuracy: 0.3562 - val_loss: 1.5295 - val_accuracy: 0.4257\n",
            "Epoch 13/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5466 - accuracy: 0.3750 - val_loss: 1.5232 - val_accuracy: 0.4455\n",
            "Epoch 14/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.5473 - accuracy: 0.3142 - val_loss: 1.5234 - val_accuracy: 0.3267\n",
            "Epoch 15/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5425 - accuracy: 0.3208 - val_loss: 1.5130 - val_accuracy: 0.3960\n",
            "Epoch 16/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5369 - accuracy: 0.3319 - val_loss: 1.5034 - val_accuracy: 0.4257\n",
            "Epoch 17/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5291 - accuracy: 0.3794 - val_loss: 1.5188 - val_accuracy: 0.3366\n",
            "Epoch 18/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5386 - accuracy: 0.3175 - val_loss: 1.5357 - val_accuracy: 0.2970\n",
            "Epoch 19/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5442 - accuracy: 0.3142 - val_loss: 1.4866 - val_accuracy: 0.3663\n",
            "Epoch 20/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5122 - accuracy: 0.4004 - val_loss: 1.4712 - val_accuracy: 0.4851\n",
            "Epoch 21/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4912 - accuracy: 0.4038 - val_loss: 1.4623 - val_accuracy: 0.4653\n",
            "Epoch 22/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4863 - accuracy: 0.4347 - val_loss: 1.4561 - val_accuracy: 0.4554\n",
            "Epoch 23/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4824 - accuracy: 0.4027 - val_loss: 1.4488 - val_accuracy: 0.4455\n",
            "Epoch 24/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4738 - accuracy: 0.4170 - val_loss: 1.4422 - val_accuracy: 0.4455\n",
            "Epoch 25/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4711 - accuracy: 0.4027 - val_loss: 1.4365 - val_accuracy: 0.4059\n",
            "Epoch 26/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4549 - accuracy: 0.4192 - val_loss: 1.4297 - val_accuracy: 0.4851\n",
            "Epoch 27/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4574 - accuracy: 0.3827 - val_loss: 1.4240 - val_accuracy: 0.4158\n",
            "Epoch 28/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4615 - accuracy: 0.4038 - val_loss: 1.4412 - val_accuracy: 0.3960\n",
            "Epoch 29/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4870 - accuracy: 0.3684 - val_loss: 1.4078 - val_accuracy: 0.4158\n",
            "Epoch 30/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4532 - accuracy: 0.3993 - val_loss: 1.4122 - val_accuracy: 0.4356\n",
            "Epoch 31/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4354 - accuracy: 0.3982 - val_loss: 1.4198 - val_accuracy: 0.3762\n",
            "Epoch 32/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4915 - accuracy: 0.3219 - val_loss: 1.4966 - val_accuracy: 0.2772\n",
            "Epoch 33/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4728 - accuracy: 0.3473 - val_loss: 1.4221 - val_accuracy: 0.4356\n",
            "Epoch 34/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4302 - accuracy: 0.4004 - val_loss: 1.4116 - val_accuracy: 0.3762\n",
            "Epoch 35/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4180 - accuracy: 0.3949 - val_loss: 1.3757 - val_accuracy: 0.4356\n",
            "Epoch 36/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4174 - accuracy: 0.3805 - val_loss: 1.3672 - val_accuracy: 0.5050\n",
            "Epoch 37/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3897 - accuracy: 0.4204 - val_loss: 1.3550 - val_accuracy: 0.4554\n",
            "Epoch 38/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3985 - accuracy: 0.4204 - val_loss: 1.3702 - val_accuracy: 0.4851\n",
            "Epoch 39/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3943 - accuracy: 0.4347 - val_loss: 1.3384 - val_accuracy: 0.4851\n",
            "Epoch 40/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3813 - accuracy: 0.4270 - val_loss: 1.3352 - val_accuracy: 0.4851\n",
            "Epoch 41/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3715 - accuracy: 0.4381 - val_loss: 1.3930 - val_accuracy: 0.4356\n",
            "Epoch 42/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4080 - accuracy: 0.3816 - val_loss: 1.3514 - val_accuracy: 0.4950\n",
            "Epoch 43/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3715 - accuracy: 0.4325 - val_loss: 1.3613 - val_accuracy: 0.4950\n",
            "Epoch 44/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3616 - accuracy: 0.4414 - val_loss: 1.3156 - val_accuracy: 0.4752\n",
            "Epoch 45/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3552 - accuracy: 0.4181 - val_loss: 1.3152 - val_accuracy: 0.5050\n",
            "Epoch 46/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3478 - accuracy: 0.4580 - val_loss: 1.3111 - val_accuracy: 0.4851\n",
            "Epoch 47/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3381 - accuracy: 0.4480 - val_loss: 1.3211 - val_accuracy: 0.4356\n",
            "Epoch 48/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3711 - accuracy: 0.3850 - val_loss: 1.3080 - val_accuracy: 0.4752\n",
            "Epoch 49/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3527 - accuracy: 0.4314 - val_loss: 1.3362 - val_accuracy: 0.4851\n",
            "Epoch 50/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3453 - accuracy: 0.4535 - val_loss: 1.3056 - val_accuracy: 0.5149\n",
            "Epoch 51/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3533 - accuracy: 0.4082 - val_loss: 1.3396 - val_accuracy: 0.4653\n",
            "Epoch 52/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3409 - accuracy: 0.4436 - val_loss: 1.2850 - val_accuracy: 0.4554\n",
            "Epoch 53/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3217 - accuracy: 0.4513 - val_loss: 1.2939 - val_accuracy: 0.5149\n",
            "Epoch 54/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3191 - accuracy: 0.4635 - val_loss: 1.2773 - val_accuracy: 0.4851\n",
            "Epoch 55/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3156 - accuracy: 0.4546 - val_loss: 1.2724 - val_accuracy: 0.4851\n",
            "Epoch 56/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3305 - accuracy: 0.4403 - val_loss: 1.3243 - val_accuracy: 0.5446\n",
            "Epoch 57/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3299 - accuracy: 0.4358 - val_loss: 1.2883 - val_accuracy: 0.4455\n",
            "Epoch 58/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3476 - accuracy: 0.4281 - val_loss: 1.2871 - val_accuracy: 0.5149\n",
            "Epoch 59/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3276 - accuracy: 0.4602 - val_loss: 1.3144 - val_accuracy: 0.4851\n",
            "Epoch 60/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3052 - accuracy: 0.4591 - val_loss: 1.2895 - val_accuracy: 0.5149\n",
            "Epoch 61/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3276 - accuracy: 0.4480 - val_loss: 1.2809 - val_accuracy: 0.4257\n",
            "Epoch 62/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3007 - accuracy: 0.4314 - val_loss: 1.2790 - val_accuracy: 0.4851\n",
            "Epoch 63/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3008 - accuracy: 0.4580 - val_loss: 1.2596 - val_accuracy: 0.4653\n",
            "Epoch 64/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3051 - accuracy: 0.4591 - val_loss: 1.2723 - val_accuracy: 0.5050\n",
            "Epoch 65/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3009 - accuracy: 0.4613 - val_loss: 1.2821 - val_accuracy: 0.3960\n",
            "Epoch 66/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3401 - accuracy: 0.4314 - val_loss: 1.3316 - val_accuracy: 0.4851\n",
            "Epoch 67/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3038 - accuracy: 0.4624 - val_loss: 1.3019 - val_accuracy: 0.4356\n",
            "Epoch 68/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3306 - accuracy: 0.4237 - val_loss: 1.3554 - val_accuracy: 0.4554\n",
            "Epoch 69/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3232 - accuracy: 0.4469 - val_loss: 1.3069 - val_accuracy: 0.4257\n",
            "Epoch 70/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3130 - accuracy: 0.4436 - val_loss: 1.2659 - val_accuracy: 0.4554\n",
            "Epoch 71/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2890 - accuracy: 0.4613 - val_loss: 1.2898 - val_accuracy: 0.5149\n",
            "Epoch 72/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2756 - accuracy: 0.4878 - val_loss: 1.2598 - val_accuracy: 0.4257\n",
            "Epoch 73/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2818 - accuracy: 0.4845 - val_loss: 1.2752 - val_accuracy: 0.4950\n",
            "Epoch 74/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2557 - accuracy: 0.5000 - val_loss: 1.2633 - val_accuracy: 0.4752\n",
            "Epoch 75/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2948 - accuracy: 0.4358 - val_loss: 1.2972 - val_accuracy: 0.4554\n",
            "Epoch 76/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3183 - accuracy: 0.4270 - val_loss: 1.2800 - val_accuracy: 0.4257\n",
            "Epoch 77/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3230 - accuracy: 0.4524 - val_loss: 1.2825 - val_accuracy: 0.4950\n",
            "Epoch 78/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2913 - accuracy: 0.4845 - val_loss: 1.2349 - val_accuracy: 0.5248\n",
            "Epoch 79/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2683 - accuracy: 0.4723 - val_loss: 1.2430 - val_accuracy: 0.5347\n",
            "Epoch 80/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2708 - accuracy: 0.4912 - val_loss: 1.2357 - val_accuracy: 0.4752\n",
            "Epoch 81/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2595 - accuracy: 0.4878 - val_loss: 1.2358 - val_accuracy: 0.5149\n",
            "Epoch 82/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2639 - accuracy: 0.4690 - val_loss: 1.2409 - val_accuracy: 0.4653\n",
            "Epoch 83/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3426 - accuracy: 0.4502 - val_loss: 1.3600 - val_accuracy: 0.3861\n",
            "Epoch 84/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3033 - accuracy: 0.4425 - val_loss: 1.2334 - val_accuracy: 0.4653\n",
            "Epoch 85/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2631 - accuracy: 0.4712 - val_loss: 1.2743 - val_accuracy: 0.4950\n",
            "Epoch 86/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2767 - accuracy: 0.4956 - val_loss: 1.2347 - val_accuracy: 0.4851\n",
            "Epoch 87/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2914 - accuracy: 0.4513 - val_loss: 1.2535 - val_accuracy: 0.5248\n",
            "Epoch 88/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2949 - accuracy: 0.4712 - val_loss: 1.2542 - val_accuracy: 0.4554\n",
            "Epoch 89/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2548 - accuracy: 0.4823 - val_loss: 1.2050 - val_accuracy: 0.5149\n",
            "Epoch 90/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2633 - accuracy: 0.4602 - val_loss: 1.2435 - val_accuracy: 0.5545\n",
            "Epoch 91/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2728 - accuracy: 0.4923 - val_loss: 1.2236 - val_accuracy: 0.4653\n",
            "Epoch 92/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2652 - accuracy: 0.4414 - val_loss: 1.2084 - val_accuracy: 0.5149\n",
            "Epoch 93/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2474 - accuracy: 0.4967 - val_loss: 1.2252 - val_accuracy: 0.4851\n",
            "Epoch 94/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2508 - accuracy: 0.4624 - val_loss: 1.2354 - val_accuracy: 0.4752\n",
            "Epoch 95/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2705 - accuracy: 0.4679 - val_loss: 1.2207 - val_accuracy: 0.5545\n",
            "Epoch 96/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2303 - accuracy: 0.5066 - val_loss: 1.1969 - val_accuracy: 0.5248\n",
            "Epoch 97/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2276 - accuracy: 0.5277 - val_loss: 1.2581 - val_accuracy: 0.4356\n",
            "Epoch 98/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3257 - accuracy: 0.4049 - val_loss: 1.2674 - val_accuracy: 0.4554\n",
            "Epoch 99/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2740 - accuracy: 0.4668 - val_loss: 1.2343 - val_accuracy: 0.4752\n",
            "Epoch 100/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2516 - accuracy: 0.4414 - val_loss: 1.2171 - val_accuracy: 0.4653\n",
            "Epoch 101/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2341 - accuracy: 0.4480 - val_loss: 1.1960 - val_accuracy: 0.5248\n",
            "Epoch 102/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2425 - accuracy: 0.4956 - val_loss: 1.1998 - val_accuracy: 0.5248\n",
            "Epoch 103/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2603 - accuracy: 0.4900 - val_loss: 1.2736 - val_accuracy: 0.4356\n",
            "Epoch 104/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2541 - accuracy: 0.4314 - val_loss: 1.2297 - val_accuracy: 0.4653\n",
            "Epoch 105/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2859 - accuracy: 0.4646 - val_loss: 1.3055 - val_accuracy: 0.4257\n",
            "Epoch 106/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2466 - accuracy: 0.4757 - val_loss: 1.2049 - val_accuracy: 0.4950\n",
            "Epoch 107/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2566 - accuracy: 0.4746 - val_loss: 1.2536 - val_accuracy: 0.5545\n",
            "Epoch 108/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2448 - accuracy: 0.5100 - val_loss: 1.2007 - val_accuracy: 0.5149\n",
            "Epoch 109/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2323 - accuracy: 0.4491 - val_loss: 1.2155 - val_accuracy: 0.5545\n",
            "Epoch 110/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2634 - accuracy: 0.4801 - val_loss: 1.1916 - val_accuracy: 0.5446\n",
            "Epoch 111/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2366 - accuracy: 0.5122 - val_loss: 1.2125 - val_accuracy: 0.5050\n",
            "Epoch 112/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2164 - accuracy: 0.4956 - val_loss: 1.1711 - val_accuracy: 0.5446\n",
            "Epoch 113/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2154 - accuracy: 0.4900 - val_loss: 1.1923 - val_accuracy: 0.4950\n",
            "Epoch 114/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2341 - accuracy: 0.4889 - val_loss: 1.2466 - val_accuracy: 0.4257\n",
            "Epoch 115/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2374 - accuracy: 0.4502 - val_loss: 1.1840 - val_accuracy: 0.5347\n",
            "Epoch 116/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2319 - accuracy: 0.5133 - val_loss: 1.2468 - val_accuracy: 0.4653\n",
            "Epoch 117/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2551 - accuracy: 0.4392 - val_loss: 1.1801 - val_accuracy: 0.5050\n",
            "Epoch 118/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2354 - accuracy: 0.5055 - val_loss: 1.1759 - val_accuracy: 0.4950\n",
            "Epoch 119/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2078 - accuracy: 0.4867 - val_loss: 1.1862 - val_accuracy: 0.4851\n",
            "Epoch 120/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2106 - accuracy: 0.5277 - val_loss: 1.1698 - val_accuracy: 0.5050\n",
            "Epoch 121/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1994 - accuracy: 0.4790 - val_loss: 1.1773 - val_accuracy: 0.5149\n",
            "Epoch 122/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2054 - accuracy: 0.5055 - val_loss: 1.1768 - val_accuracy: 0.4950\n",
            "Epoch 123/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1917 - accuracy: 0.5111 - val_loss: 1.1733 - val_accuracy: 0.5347\n",
            "Epoch 124/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1995 - accuracy: 0.5254 - val_loss: 1.1721 - val_accuracy: 0.4851\n",
            "Epoch 125/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2094 - accuracy: 0.4878 - val_loss: 1.2029 - val_accuracy: 0.5050\n",
            "Epoch 126/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2090 - accuracy: 0.5066 - val_loss: 1.1690 - val_accuracy: 0.4950\n",
            "Epoch 127/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2207 - accuracy: 0.4934 - val_loss: 1.1978 - val_accuracy: 0.5446\n",
            "Epoch 128/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5321 - val_loss: 1.1861 - val_accuracy: 0.5149\n",
            "Epoch 129/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2239 - accuracy: 0.4546 - val_loss: 1.1757 - val_accuracy: 0.4554\n",
            "Epoch 130/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2064 - accuracy: 0.5166 - val_loss: 1.1697 - val_accuracy: 0.5347\n",
            "Epoch 131/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2150 - accuracy: 0.5022 - val_loss: 1.2041 - val_accuracy: 0.5545\n",
            "Epoch 132/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2022 - accuracy: 0.5144 - val_loss: 1.1602 - val_accuracy: 0.5050\n",
            "Epoch 133/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1931 - accuracy: 0.5210 - val_loss: 1.1619 - val_accuracy: 0.5347\n",
            "Epoch 134/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1931 - accuracy: 0.5221 - val_loss: 1.1646 - val_accuracy: 0.4653\n",
            "Epoch 135/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1839 - accuracy: 0.5044 - val_loss: 1.1544 - val_accuracy: 0.5545\n",
            "Epoch 136/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2039 - accuracy: 0.5354 - val_loss: 1.1401 - val_accuracy: 0.5248\n",
            "Epoch 137/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1672 - accuracy: 0.5442 - val_loss: 1.1542 - val_accuracy: 0.5743\n",
            "Epoch 138/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1735 - accuracy: 0.5343 - val_loss: 1.1502 - val_accuracy: 0.5050\n",
            "Epoch 139/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1777 - accuracy: 0.5376 - val_loss: 1.1908 - val_accuracy: 0.5644\n",
            "Epoch 140/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1942 - accuracy: 0.5144 - val_loss: 1.1660 - val_accuracy: 0.5149\n",
            "Epoch 141/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1942 - accuracy: 0.5122 - val_loss: 1.1297 - val_accuracy: 0.5347\n",
            "Epoch 142/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1774 - accuracy: 0.5365 - val_loss: 1.1370 - val_accuracy: 0.5743\n",
            "Epoch 143/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1680 - accuracy: 0.5299 - val_loss: 1.1998 - val_accuracy: 0.4653\n",
            "Epoch 144/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2252 - accuracy: 0.4679 - val_loss: 1.1447 - val_accuracy: 0.5545\n",
            "Epoch 145/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1758 - accuracy: 0.5376 - val_loss: 1.1550 - val_accuracy: 0.5149\n",
            "Epoch 146/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1797 - accuracy: 0.5277 - val_loss: 1.1544 - val_accuracy: 0.5446\n",
            "Epoch 147/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1918 - accuracy: 0.5420 - val_loss: 1.1334 - val_accuracy: 0.5149\n",
            "Epoch 148/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1678 - accuracy: 0.5387 - val_loss: 1.1392 - val_accuracy: 0.5545\n",
            "Epoch 149/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1785 - accuracy: 0.5210 - val_loss: 1.1438 - val_accuracy: 0.5347\n",
            "Epoch 150/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1745 - accuracy: 0.5077 - val_loss: 1.1498 - val_accuracy: 0.5050\n",
            "Epoch 151/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1944 - accuracy: 0.5066 - val_loss: 1.1815 - val_accuracy: 0.5149\n",
            "Epoch 152/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1710 - accuracy: 0.5299 - val_loss: 1.1303 - val_accuracy: 0.5149\n",
            "Epoch 153/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1738 - accuracy: 0.5077 - val_loss: 1.1436 - val_accuracy: 0.4950\n",
            "Epoch 154/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1928 - accuracy: 0.5133 - val_loss: 1.1515 - val_accuracy: 0.4950\n",
            "Epoch 155/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1575 - accuracy: 0.5431 - val_loss: 1.1248 - val_accuracy: 0.5446\n",
            "Epoch 156/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1691 - accuracy: 0.5077 - val_loss: 1.1196 - val_accuracy: 0.5446\n",
            "Epoch 157/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1628 - accuracy: 0.5332 - val_loss: 1.1363 - val_accuracy: 0.5347\n",
            "Epoch 158/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1502 - accuracy: 0.5509 - val_loss: 1.1082 - val_accuracy: 0.5149\n",
            "Epoch 159/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1591 - accuracy: 0.5398 - val_loss: 1.1387 - val_accuracy: 0.6238\n",
            "Epoch 160/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1551 - accuracy: 0.5420 - val_loss: 1.1063 - val_accuracy: 0.5446\n",
            "Epoch 161/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1417 - accuracy: 0.5476 - val_loss: 1.1303 - val_accuracy: 0.5941\n",
            "Epoch 162/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1469 - accuracy: 0.5553 - val_loss: 1.1037 - val_accuracy: 0.5149\n",
            "Epoch 163/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1398 - accuracy: 0.5387 - val_loss: 1.1083 - val_accuracy: 0.5347\n",
            "Epoch 164/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1654 - accuracy: 0.5022 - val_loss: 1.1953 - val_accuracy: 0.4257\n",
            "Epoch 165/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1734 - accuracy: 0.4900 - val_loss: 1.0986 - val_accuracy: 0.5644\n",
            "Epoch 166/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1354 - accuracy: 0.5243 - val_loss: 1.1088 - val_accuracy: 0.5347\n",
            "Epoch 167/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1315 - accuracy: 0.5398 - val_loss: 1.1091 - val_accuracy: 0.5248\n",
            "Epoch 168/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1518 - accuracy: 0.5575 - val_loss: 1.1292 - val_accuracy: 0.5941\n",
            "Epoch 169/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1441 - accuracy: 0.5520 - val_loss: 1.1164 - val_accuracy: 0.4950\n",
            "Epoch 170/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1473 - accuracy: 0.5122 - val_loss: 1.0858 - val_accuracy: 0.5545\n",
            "Epoch 171/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1335 - accuracy: 0.5277 - val_loss: 1.1022 - val_accuracy: 0.5743\n",
            "Epoch 172/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1440 - accuracy: 0.5553 - val_loss: 1.1201 - val_accuracy: 0.4653\n",
            "Epoch 173/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1447 - accuracy: 0.5254 - val_loss: 1.1056 - val_accuracy: 0.5446\n",
            "Epoch 174/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1375 - accuracy: 0.5520 - val_loss: 1.0940 - val_accuracy: 0.4950\n",
            "Epoch 175/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1250 - accuracy: 0.5531 - val_loss: 1.1111 - val_accuracy: 0.5446\n",
            "Epoch 176/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1226 - accuracy: 0.5476 - val_loss: 1.0860 - val_accuracy: 0.5743\n",
            "Epoch 177/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1297 - accuracy: 0.5542 - val_loss: 1.1158 - val_accuracy: 0.4950\n",
            "Epoch 178/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1284 - accuracy: 0.5553 - val_loss: 1.0913 - val_accuracy: 0.5743\n",
            "Epoch 179/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1342 - accuracy: 0.5487 - val_loss: 1.1278 - val_accuracy: 0.5248\n",
            "Epoch 180/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1369 - accuracy: 0.5243 - val_loss: 1.0684 - val_accuracy: 0.5545\n",
            "Epoch 181/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1122 - accuracy: 0.5586 - val_loss: 1.0768 - val_accuracy: 0.5446\n",
            "Epoch 182/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1507 - accuracy: 0.5288 - val_loss: 1.1211 - val_accuracy: 0.4950\n",
            "Epoch 183/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1257 - accuracy: 0.5299 - val_loss: 1.0715 - val_accuracy: 0.5644\n",
            "Epoch 184/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1094 - accuracy: 0.5575 - val_loss: 1.0827 - val_accuracy: 0.5149\n",
            "Epoch 185/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1232 - accuracy: 0.5431 - val_loss: 1.1211 - val_accuracy: 0.6040\n",
            "Epoch 186/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1316 - accuracy: 0.5719 - val_loss: 1.0847 - val_accuracy: 0.5149\n",
            "Epoch 187/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1172 - accuracy: 0.5442 - val_loss: 1.0833 - val_accuracy: 0.5842\n",
            "Epoch 188/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1121 - accuracy: 0.5597 - val_loss: 1.0825 - val_accuracy: 0.5545\n",
            "Epoch 189/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1514 - accuracy: 0.5509 - val_loss: 1.1197 - val_accuracy: 0.5248\n",
            "Epoch 190/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1164 - accuracy: 0.5608 - val_loss: 1.0726 - val_accuracy: 0.5545\n",
            "Epoch 191/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1045 - accuracy: 0.5631 - val_loss: 1.0581 - val_accuracy: 0.5248\n",
            "Epoch 192/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1189 - accuracy: 0.5387 - val_loss: 1.1069 - val_accuracy: 0.5941\n",
            "Epoch 193/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1428 - accuracy: 0.5631 - val_loss: 1.0935 - val_accuracy: 0.5941\n",
            "Epoch 194/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1114 - accuracy: 0.5631 - val_loss: 1.1070 - val_accuracy: 0.4752\n",
            "Epoch 195/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1214 - accuracy: 0.5542 - val_loss: 1.0626 - val_accuracy: 0.5743\n",
            "Epoch 196/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1034 - accuracy: 0.5520 - val_loss: 1.0678 - val_accuracy: 0.6238\n",
            "Epoch 197/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0870 - accuracy: 0.5730 - val_loss: 1.0522 - val_accuracy: 0.5941\n",
            "Epoch 198/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0967 - accuracy: 0.5719 - val_loss: 1.0608 - val_accuracy: 0.5941\n",
            "Epoch 199/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1022 - accuracy: 0.5553 - val_loss: 1.0750 - val_accuracy: 0.5545\n",
            "Epoch 200/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1112 - accuracy: 0.5929 - val_loss: 1.0480 - val_accuracy: 0.5347\n",
            "Epoch 201/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0863 - accuracy: 0.5664 - val_loss: 1.0777 - val_accuracy: 0.6337\n",
            "Epoch 202/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0875 - accuracy: 0.6018 - val_loss: 1.0580 - val_accuracy: 0.5347\n",
            "Epoch 203/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0832 - accuracy: 0.5719 - val_loss: 1.0610 - val_accuracy: 0.5347\n",
            "Epoch 204/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1329 - accuracy: 0.5243 - val_loss: 1.1452 - val_accuracy: 0.5050\n",
            "Epoch 205/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1181 - accuracy: 0.5553 - val_loss: 1.0475 - val_accuracy: 0.5347\n",
            "Epoch 206/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0833 - accuracy: 0.5719 - val_loss: 1.0363 - val_accuracy: 0.5743\n",
            "Epoch 207/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0763 - accuracy: 0.5675 - val_loss: 1.0884 - val_accuracy: 0.6040\n",
            "Epoch 208/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0940 - accuracy: 0.5907 - val_loss: 1.0618 - val_accuracy: 0.5347\n",
            "Epoch 209/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0837 - accuracy: 0.5619 - val_loss: 1.0942 - val_accuracy: 0.6238\n",
            "Epoch 210/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0958 - accuracy: 0.5730 - val_loss: 1.0310 - val_accuracy: 0.5644\n",
            "Epoch 211/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0900 - accuracy: 0.5675 - val_loss: 1.0568 - val_accuracy: 0.5347\n",
            "Epoch 212/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0954 - accuracy: 0.5531 - val_loss: 1.0361 - val_accuracy: 0.5941\n",
            "Epoch 213/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0766 - accuracy: 0.5796 - val_loss: 1.0870 - val_accuracy: 0.6040\n",
            "Epoch 214/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0846 - accuracy: 0.5730 - val_loss: 1.0417 - val_accuracy: 0.6040\n",
            "Epoch 215/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0881 - accuracy: 0.5841 - val_loss: 1.0240 - val_accuracy: 0.5842\n",
            "Epoch 216/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0939 - accuracy: 0.5631 - val_loss: 1.0343 - val_accuracy: 0.6436\n",
            "Epoch 217/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0675 - accuracy: 0.6139 - val_loss: 1.0173 - val_accuracy: 0.5644\n",
            "Epoch 218/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0665 - accuracy: 0.5885 - val_loss: 1.0579 - val_accuracy: 0.6040\n",
            "Epoch 219/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0896 - accuracy: 0.5918 - val_loss: 1.0748 - val_accuracy: 0.5149\n",
            "Epoch 220/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0959 - accuracy: 0.5653 - val_loss: 1.0281 - val_accuracy: 0.6139\n",
            "Epoch 221/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0606 - accuracy: 0.5763 - val_loss: 1.0371 - val_accuracy: 0.6238\n",
            "Epoch 222/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0664 - accuracy: 0.6018 - val_loss: 1.0238 - val_accuracy: 0.5545\n",
            "Epoch 223/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0772 - accuracy: 0.5642 - val_loss: 1.0177 - val_accuracy: 0.5743\n",
            "Epoch 224/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0644 - accuracy: 0.5830 - val_loss: 1.0892 - val_accuracy: 0.5545\n",
            "Epoch 225/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0861 - accuracy: 0.5730 - val_loss: 1.0168 - val_accuracy: 0.5446\n",
            "Epoch 226/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0598 - accuracy: 0.5852 - val_loss: 1.0186 - val_accuracy: 0.5446\n",
            "Epoch 227/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0680 - accuracy: 0.5708 - val_loss: 1.1329 - val_accuracy: 0.5446\n",
            "Epoch 228/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0847 - accuracy: 0.5675 - val_loss: 1.0053 - val_accuracy: 0.5545\n",
            "Epoch 229/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0615 - accuracy: 0.5896 - val_loss: 1.0041 - val_accuracy: 0.6139\n",
            "Epoch 230/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0482 - accuracy: 0.5907 - val_loss: 1.0780 - val_accuracy: 0.5446\n",
            "Epoch 231/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0762 - accuracy: 0.5730 - val_loss: 1.0526 - val_accuracy: 0.6040\n",
            "Epoch 232/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0827 - accuracy: 0.5608 - val_loss: 1.0034 - val_accuracy: 0.6337\n",
            "Epoch 233/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0312 - accuracy: 0.6084 - val_loss: 0.9956 - val_accuracy: 0.5743\n",
            "Epoch 234/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0450 - accuracy: 0.6040 - val_loss: 0.9953 - val_accuracy: 0.6238\n",
            "Epoch 235/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0557 - accuracy: 0.5940 - val_loss: 1.0058 - val_accuracy: 0.5644\n",
            "Epoch 236/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0391 - accuracy: 0.5985 - val_loss: 1.0167 - val_accuracy: 0.6436\n",
            "Epoch 237/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0494 - accuracy: 0.6217 - val_loss: 0.9954 - val_accuracy: 0.5941\n",
            "Epoch 238/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0690 - accuracy: 0.5796 - val_loss: 1.0234 - val_accuracy: 0.6040\n",
            "Epoch 239/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0521 - accuracy: 0.5841 - val_loss: 0.9991 - val_accuracy: 0.6238\n",
            "Epoch 240/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0458 - accuracy: 0.5918 - val_loss: 1.0038 - val_accuracy: 0.6139\n",
            "Epoch 241/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0729 - accuracy: 0.5653 - val_loss: 1.0208 - val_accuracy: 0.5842\n",
            "Epoch 242/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0625 - accuracy: 0.5841 - val_loss: 1.0221 - val_accuracy: 0.5941\n",
            "Epoch 243/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0746 - accuracy: 0.5730 - val_loss: 1.0696 - val_accuracy: 0.5050\n",
            "Epoch 244/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0800 - accuracy: 0.5985 - val_loss: 0.9787 - val_accuracy: 0.6139\n",
            "Epoch 245/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0634 - accuracy: 0.5841 - val_loss: 1.0305 - val_accuracy: 0.6040\n",
            "Epoch 246/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0514 - accuracy: 0.5885 - val_loss: 0.9925 - val_accuracy: 0.6436\n",
            "Epoch 247/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0265 - accuracy: 0.6040 - val_loss: 0.9983 - val_accuracy: 0.5743\n",
            "Epoch 248/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0589 - accuracy: 0.5686 - val_loss: 1.0555 - val_accuracy: 0.5347\n",
            "Epoch 249/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0519 - accuracy: 0.5597 - val_loss: 1.0160 - val_accuracy: 0.6040\n",
            "Epoch 250/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0349 - accuracy: 0.6073 - val_loss: 0.9695 - val_accuracy: 0.6337\n",
            "Epoch 251/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0092 - accuracy: 0.6449 - val_loss: 0.9761 - val_accuracy: 0.5743\n",
            "Epoch 252/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0133 - accuracy: 0.6272 - val_loss: 0.9786 - val_accuracy: 0.6535\n",
            "Epoch 253/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0131 - accuracy: 0.6372 - val_loss: 0.9959 - val_accuracy: 0.6436\n",
            "Epoch 254/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0248 - accuracy: 0.6040 - val_loss: 0.9640 - val_accuracy: 0.6139\n",
            "Epoch 255/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0298 - accuracy: 0.5874 - val_loss: 1.0096 - val_accuracy: 0.6040\n",
            "Epoch 256/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0411 - accuracy: 0.6095 - val_loss: 0.9994 - val_accuracy: 0.5842\n",
            "Epoch 257/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0243 - accuracy: 0.6018 - val_loss: 1.0036 - val_accuracy: 0.5248\n",
            "Epoch 258/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0245 - accuracy: 0.6018 - val_loss: 0.9649 - val_accuracy: 0.6139\n",
            "Epoch 259/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0348 - accuracy: 0.6062 - val_loss: 1.0067 - val_accuracy: 0.5941\n",
            "Epoch 260/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0141 - accuracy: 0.6040 - val_loss: 0.9779 - val_accuracy: 0.6733\n",
            "Epoch 261/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0304 - accuracy: 0.6195 - val_loss: 0.9715 - val_accuracy: 0.6337\n",
            "Epoch 262/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0209 - accuracy: 0.6184 - val_loss: 0.9616 - val_accuracy: 0.6436\n",
            "Epoch 263/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9873 - accuracy: 0.6449 - val_loss: 0.9498 - val_accuracy: 0.6535\n",
            "Epoch 264/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9953 - accuracy: 0.6449 - val_loss: 0.9571 - val_accuracy: 0.6337\n",
            "Epoch 265/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9922 - accuracy: 0.6250 - val_loss: 0.9549 - val_accuracy: 0.6535\n",
            "Epoch 266/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9900 - accuracy: 0.6305 - val_loss: 0.9507 - val_accuracy: 0.6040\n",
            "Epoch 267/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0037 - accuracy: 0.6250 - val_loss: 0.9767 - val_accuracy: 0.6634\n",
            "Epoch 268/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0002 - accuracy: 0.6217 - val_loss: 0.9941 - val_accuracy: 0.6634\n",
            "Epoch 269/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9973 - accuracy: 0.6449 - val_loss: 0.9462 - val_accuracy: 0.6139\n",
            "Epoch 270/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9919 - accuracy: 0.6272 - val_loss: 0.9609 - val_accuracy: 0.5941\n",
            "Epoch 271/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0074 - accuracy: 0.6073 - val_loss: 0.9391 - val_accuracy: 0.6436\n",
            "Epoch 272/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0069 - accuracy: 0.6228 - val_loss: 0.9729 - val_accuracy: 0.6238\n",
            "Epoch 273/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0317 - accuracy: 0.5985 - val_loss: 0.9954 - val_accuracy: 0.6436\n",
            "Epoch 274/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0372 - accuracy: 0.5985 - val_loss: 0.9475 - val_accuracy: 0.6634\n",
            "Epoch 275/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0171 - accuracy: 0.6272 - val_loss: 1.0046 - val_accuracy: 0.5644\n",
            "Epoch 276/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9979 - accuracy: 0.6250 - val_loss: 0.9493 - val_accuracy: 0.6535\n",
            "Epoch 277/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9712 - accuracy: 0.6593 - val_loss: 0.9340 - val_accuracy: 0.6733\n",
            "Epoch 278/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9932 - accuracy: 0.6128 - val_loss: 0.9413 - val_accuracy: 0.6832\n",
            "Epoch 279/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9984 - accuracy: 0.6449 - val_loss: 0.9656 - val_accuracy: 0.5941\n",
            "Epoch 280/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9964 - accuracy: 0.6338 - val_loss: 0.9496 - val_accuracy: 0.6139\n",
            "Epoch 281/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9831 - accuracy: 0.6272 - val_loss: 1.0899 - val_accuracy: 0.5842\n",
            "Epoch 282/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0284 - accuracy: 0.6150 - val_loss: 0.9224 - val_accuracy: 0.6535\n",
            "Epoch 283/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0279 - accuracy: 0.6106 - val_loss: 1.1404 - val_accuracy: 0.4455\n",
            "Epoch 284/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0906 - accuracy: 0.5642 - val_loss: 0.9572 - val_accuracy: 0.6832\n",
            "Epoch 285/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0194 - accuracy: 0.5962 - val_loss: 0.9674 - val_accuracy: 0.6634\n",
            "Epoch 286/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9908 - accuracy: 0.6283 - val_loss: 0.9836 - val_accuracy: 0.6436\n",
            "Epoch 287/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0110 - accuracy: 0.5885 - val_loss: 0.9635 - val_accuracy: 0.6238\n",
            "Epoch 288/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9995 - accuracy: 0.6294 - val_loss: 0.9773 - val_accuracy: 0.5644\n",
            "Epoch 289/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9813 - accuracy: 0.6416 - val_loss: 0.9397 - val_accuracy: 0.6139\n",
            "Epoch 290/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9650 - accuracy: 0.6383 - val_loss: 0.9512 - val_accuracy: 0.6139\n",
            "Epoch 291/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9663 - accuracy: 0.6449 - val_loss: 0.9418 - val_accuracy: 0.6436\n",
            "Epoch 292/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9641 - accuracy: 0.6781 - val_loss: 0.9343 - val_accuracy: 0.6733\n",
            "Epoch 293/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9671 - accuracy: 0.6493 - val_loss: 0.9693 - val_accuracy: 0.6238\n",
            "Epoch 294/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9709 - accuracy: 0.6560 - val_loss: 0.9260 - val_accuracy: 0.6832\n",
            "Epoch 295/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9516 - accuracy: 0.6560 - val_loss: 0.9754 - val_accuracy: 0.6535\n",
            "Epoch 296/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9850 - accuracy: 0.6283 - val_loss: 0.9333 - val_accuracy: 0.5644\n",
            "Epoch 297/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9876 - accuracy: 0.6239 - val_loss: 0.9128 - val_accuracy: 0.6337\n",
            "Epoch 298/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9530 - accuracy: 0.6482 - val_loss: 0.9152 - val_accuracy: 0.6634\n",
            "Epoch 299/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9507 - accuracy: 0.6538 - val_loss: 0.9122 - val_accuracy: 0.7030\n",
            "Epoch 300/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9681 - accuracy: 0.6571 - val_loss: 0.9155 - val_accuracy: 0.6436\n",
            "Epoch 301/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9704 - accuracy: 0.6471 - val_loss: 0.9584 - val_accuracy: 0.6634\n",
            "Epoch 302/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9801 - accuracy: 0.6316 - val_loss: 0.9119 - val_accuracy: 0.6832\n",
            "Epoch 303/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9557 - accuracy: 0.6405 - val_loss: 0.9169 - val_accuracy: 0.6436\n",
            "Epoch 304/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9437 - accuracy: 0.6593 - val_loss: 0.9325 - val_accuracy: 0.6238\n",
            "Epoch 305/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9684 - accuracy: 0.6460 - val_loss: 0.9078 - val_accuracy: 0.6832\n",
            "Epoch 306/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9469 - accuracy: 0.6504 - val_loss: 0.9336 - val_accuracy: 0.7228\n",
            "Epoch 307/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9433 - accuracy: 0.6781 - val_loss: 0.8919 - val_accuracy: 0.7030\n",
            "Epoch 308/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9314 - accuracy: 0.6748 - val_loss: 0.8873 - val_accuracy: 0.6535\n",
            "Epoch 309/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9374 - accuracy: 0.6936 - val_loss: 0.9166 - val_accuracy: 0.6634\n",
            "Epoch 310/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9684 - accuracy: 0.6206 - val_loss: 0.9578 - val_accuracy: 0.6337\n",
            "Epoch 311/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9766 - accuracy: 0.6615 - val_loss: 0.9422 - val_accuracy: 0.6139\n",
            "Epoch 312/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0051 - accuracy: 0.5962 - val_loss: 1.0409 - val_accuracy: 0.6436\n",
            "Epoch 313/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0015 - accuracy: 0.6128 - val_loss: 0.8934 - val_accuracy: 0.6931\n",
            "Epoch 314/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9461 - accuracy: 0.6383 - val_loss: 0.9312 - val_accuracy: 0.6535\n",
            "Epoch 315/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9473 - accuracy: 0.6582 - val_loss: 0.8948 - val_accuracy: 0.6733\n",
            "Epoch 316/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9201 - accuracy: 0.6825 - val_loss: 0.8974 - val_accuracy: 0.7129\n",
            "Epoch 317/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9563 - accuracy: 0.6305 - val_loss: 0.8851 - val_accuracy: 0.6634\n",
            "Epoch 318/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9257 - accuracy: 0.6781 - val_loss: 0.8890 - val_accuracy: 0.6832\n",
            "Epoch 319/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9242 - accuracy: 0.6892 - val_loss: 0.8790 - val_accuracy: 0.6733\n",
            "Epoch 320/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9212 - accuracy: 0.6670 - val_loss: 0.9058 - val_accuracy: 0.6931\n",
            "Epoch 321/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9226 - accuracy: 0.6593 - val_loss: 0.9303 - val_accuracy: 0.6238\n",
            "Epoch 322/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9235 - accuracy: 0.6681 - val_loss: 0.8901 - val_accuracy: 0.6832\n",
            "Epoch 323/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9075 - accuracy: 0.6903 - val_loss: 0.8811 - val_accuracy: 0.6931\n",
            "Epoch 324/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9198 - accuracy: 0.6803 - val_loss: 0.9104 - val_accuracy: 0.6733\n",
            "Epoch 325/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9286 - accuracy: 0.6748 - val_loss: 0.8849 - val_accuracy: 0.6535\n",
            "Epoch 326/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9263 - accuracy: 0.6670 - val_loss: 0.8868 - val_accuracy: 0.7129\n",
            "Epoch 327/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9134 - accuracy: 0.6869 - val_loss: 0.9144 - val_accuracy: 0.5644\n",
            "Epoch 328/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9419 - accuracy: 0.6438 - val_loss: 0.8668 - val_accuracy: 0.6535\n",
            "Epoch 329/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9173 - accuracy: 0.6748 - val_loss: 0.8580 - val_accuracy: 0.7030\n",
            "Epoch 330/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9081 - accuracy: 0.6770 - val_loss: 0.8773 - val_accuracy: 0.7030\n",
            "Epoch 331/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9138 - accuracy: 0.6626 - val_loss: 0.8580 - val_accuracy: 0.6634\n",
            "Epoch 332/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9247 - accuracy: 0.6648 - val_loss: 0.8690 - val_accuracy: 0.7030\n",
            "Epoch 333/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9111 - accuracy: 0.6615 - val_loss: 0.8824 - val_accuracy: 0.6832\n",
            "Epoch 334/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9257 - accuracy: 0.6549 - val_loss: 0.9360 - val_accuracy: 0.6634\n",
            "Epoch 335/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9270 - accuracy: 0.6648 - val_loss: 0.8915 - val_accuracy: 0.6337\n",
            "Epoch 336/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9254 - accuracy: 0.6792 - val_loss: 0.8755 - val_accuracy: 0.7030\n",
            "Epoch 337/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9083 - accuracy: 0.6881 - val_loss: 0.8971 - val_accuracy: 0.6931\n",
            "Epoch 338/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9319 - accuracy: 0.6449 - val_loss: 0.8857 - val_accuracy: 0.7129\n",
            "Epoch 339/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9127 - accuracy: 0.6803 - val_loss: 0.8605 - val_accuracy: 0.7129\n",
            "Epoch 340/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9068 - accuracy: 0.6836 - val_loss: 0.8662 - val_accuracy: 0.6535\n",
            "Epoch 341/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9088 - accuracy: 0.6792 - val_loss: 0.9654 - val_accuracy: 0.5149\n",
            "Epoch 342/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9926 - accuracy: 0.6239 - val_loss: 0.8712 - val_accuracy: 0.6535\n",
            "Epoch 343/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9148 - accuracy: 0.6560 - val_loss: 0.8478 - val_accuracy: 0.7129\n",
            "Epoch 344/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9155 - accuracy: 0.6604 - val_loss: 0.8417 - val_accuracy: 0.7030\n",
            "Epoch 345/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8977 - accuracy: 0.6803 - val_loss: 0.9444 - val_accuracy: 0.6634\n",
            "Epoch 346/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9102 - accuracy: 0.6836 - val_loss: 0.8590 - val_accuracy: 0.6733\n",
            "Epoch 347/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9092 - accuracy: 0.6759 - val_loss: 0.8877 - val_accuracy: 0.7129\n",
            "Epoch 348/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8886 - accuracy: 0.7002 - val_loss: 0.8769 - val_accuracy: 0.6634\n",
            "Epoch 349/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9119 - accuracy: 0.6626 - val_loss: 0.9030 - val_accuracy: 0.6040\n",
            "Epoch 350/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9592 - accuracy: 0.6062 - val_loss: 0.9939 - val_accuracy: 0.5644\n",
            "Epoch 351/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9238 - accuracy: 0.6427 - val_loss: 0.8437 - val_accuracy: 0.7228\n",
            "Epoch 352/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8797 - accuracy: 0.6869 - val_loss: 0.8321 - val_accuracy: 0.6634\n",
            "Epoch 353/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8830 - accuracy: 0.6825 - val_loss: 0.8434 - val_accuracy: 0.6634\n",
            "Epoch 354/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9088 - accuracy: 0.6416 - val_loss: 0.9035 - val_accuracy: 0.6238\n",
            "Epoch 355/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8978 - accuracy: 0.6715 - val_loss: 0.8636 - val_accuracy: 0.7030\n",
            "Epoch 356/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8904 - accuracy: 0.6781 - val_loss: 0.8538 - val_accuracy: 0.6733\n",
            "Epoch 357/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8874 - accuracy: 0.6914 - val_loss: 0.8275 - val_accuracy: 0.6931\n",
            "Epoch 358/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8799 - accuracy: 0.6847 - val_loss: 0.8510 - val_accuracy: 0.6733\n",
            "Epoch 359/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8818 - accuracy: 0.6858 - val_loss: 0.8258 - val_accuracy: 0.7327\n",
            "Epoch 360/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8795 - accuracy: 0.6726 - val_loss: 0.8440 - val_accuracy: 0.7030\n",
            "Epoch 361/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8847 - accuracy: 0.6704 - val_loss: 0.9402 - val_accuracy: 0.5941\n",
            "Epoch 362/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9278 - accuracy: 0.6482 - val_loss: 0.8607 - val_accuracy: 0.6634\n",
            "Epoch 363/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9086 - accuracy: 0.6549 - val_loss: 0.8330 - val_accuracy: 0.7624\n",
            "Epoch 364/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8917 - accuracy: 0.6604 - val_loss: 0.9604 - val_accuracy: 0.6436\n",
            "Epoch 365/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9434 - accuracy: 0.6338 - val_loss: 0.8906 - val_accuracy: 0.6535\n",
            "Epoch 366/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8931 - accuracy: 0.6847 - val_loss: 0.8831 - val_accuracy: 0.6733\n",
            "Epoch 367/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9187 - accuracy: 0.6593 - val_loss: 0.8332 - val_accuracy: 0.6535\n",
            "Epoch 368/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8742 - accuracy: 0.6914 - val_loss: 0.8354 - val_accuracy: 0.6634\n",
            "Epoch 369/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8743 - accuracy: 0.6980 - val_loss: 0.8200 - val_accuracy: 0.7129\n",
            "Epoch 370/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8885 - accuracy: 0.6692 - val_loss: 0.8834 - val_accuracy: 0.6535\n",
            "Epoch 371/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9008 - accuracy: 0.7146 - val_loss: 0.8594 - val_accuracy: 0.6931\n",
            "Epoch 372/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8871 - accuracy: 0.6704 - val_loss: 0.8893 - val_accuracy: 0.7030\n",
            "Epoch 373/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8677 - accuracy: 0.7091 - val_loss: 0.8306 - val_accuracy: 0.6931\n",
            "Epoch 374/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8953 - accuracy: 0.6637 - val_loss: 0.8472 - val_accuracy: 0.7228\n",
            "Epoch 375/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8502 - accuracy: 0.7268 - val_loss: 0.8292 - val_accuracy: 0.7426\n",
            "Epoch 376/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8790 - accuracy: 0.6847 - val_loss: 0.8847 - val_accuracy: 0.7129\n",
            "Epoch 377/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8656 - accuracy: 0.7013 - val_loss: 0.8184 - val_accuracy: 0.7327\n",
            "Epoch 378/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8565 - accuracy: 0.7146 - val_loss: 0.8771 - val_accuracy: 0.6931\n",
            "Epoch 379/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8820 - accuracy: 0.6593 - val_loss: 0.8463 - val_accuracy: 0.6535\n",
            "Epoch 380/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8846 - accuracy: 0.6781 - val_loss: 0.8203 - val_accuracy: 0.7030\n",
            "Epoch 381/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8601 - accuracy: 0.7002 - val_loss: 0.8640 - val_accuracy: 0.7228\n",
            "Epoch 382/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8813 - accuracy: 0.6825 - val_loss: 0.8380 - val_accuracy: 0.7030\n",
            "Epoch 383/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8786 - accuracy: 0.6858 - val_loss: 0.9124 - val_accuracy: 0.6832\n",
            "Epoch 384/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9299 - accuracy: 0.6527 - val_loss: 0.8737 - val_accuracy: 0.6733\n",
            "Epoch 385/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8549 - accuracy: 0.7013 - val_loss: 0.8227 - val_accuracy: 0.6733\n",
            "Epoch 386/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8568 - accuracy: 0.6958 - val_loss: 0.8394 - val_accuracy: 0.7327\n",
            "Epoch 387/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8718 - accuracy: 0.6980 - val_loss: 0.8712 - val_accuracy: 0.6832\n",
            "Epoch 388/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8878 - accuracy: 0.6615 - val_loss: 0.9629 - val_accuracy: 0.6436\n",
            "Epoch 389/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9122 - accuracy: 0.6759 - val_loss: 0.8054 - val_accuracy: 0.7525\n",
            "Epoch 390/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8562 - accuracy: 0.6914 - val_loss: 0.8348 - val_accuracy: 0.7129\n",
            "Epoch 391/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8319 - accuracy: 0.7312 - val_loss: 0.7886 - val_accuracy: 0.7030\n",
            "Epoch 392/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8294 - accuracy: 0.7246 - val_loss: 0.8438 - val_accuracy: 0.7129\n",
            "Epoch 393/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8381 - accuracy: 0.7223 - val_loss: 0.7891 - val_accuracy: 0.7327\n",
            "Epoch 394/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8236 - accuracy: 0.7223 - val_loss: 0.8229 - val_accuracy: 0.7525\n",
            "Epoch 395/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8277 - accuracy: 0.7091 - val_loss: 0.7992 - val_accuracy: 0.7228\n",
            "Epoch 396/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8331 - accuracy: 0.7113 - val_loss: 0.8201 - val_accuracy: 0.7228\n",
            "Epoch 397/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8338 - accuracy: 0.7290 - val_loss: 0.7888 - val_accuracy: 0.7426\n",
            "Epoch 398/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8205 - accuracy: 0.7268 - val_loss: 0.7849 - val_accuracy: 0.7426\n",
            "Epoch 399/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8159 - accuracy: 0.7257 - val_loss: 0.7859 - val_accuracy: 0.7129\n",
            "Epoch 400/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8173 - accuracy: 0.7223 - val_loss: 0.7944 - val_accuracy: 0.6832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd5ade7f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY7s4XJoEU97"
      },
      "source": [
        "Оценим ее точность: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnYnQY_cEWe2",
        "outputId": "5ad70ba1-d2c3-4e6d-b5d5-59b134e084fb"
      },
      "source": [
        "\n",
        "score = model3.evaluate(x_test.reshape(int(1500*0.33),1024), y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.9052936434745789\n",
            "Test accuracy: 0.6565656661987305\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}